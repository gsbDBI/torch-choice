{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication Materials for the Torch-Choice Paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Author: Tianyu Du\n",
    "> \n",
    "> Email: `tianyudu@stanford.edu`\n",
    "\n",
    "This repository contains the replication materials for the paper \"Torch-Choice: A Library for Choice Models in PyTorch\". Due to the limited space in the main paper, we have omitted some codes and outputs in the paper. This repository contains the full version of codes mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_choice\n",
    "from torch_choice import run\n",
    "from tqdm import tqdm\n",
    "from torch_choice.data import ChoiceDataset, JointDataset, utils, load_mode_canada_dataset, load_house_cooling_dataset_v1\n",
    "from torch_choice.model import ConditionalLogitModel, NestedLogitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed to enforce reproducibility.\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_choice.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>consumer_id</th>\n",
       "      <th>car</th>\n",
       "      <th>purchase</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>speed</th>\n",
       "      <th>discount</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46.699997</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.699997</td>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>European</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.699997</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.699997</td>\n",
       "      <td>8</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  session_id  consumer_id       car  purchase  gender     income  \\\n",
       "0          1           1            1  American         1       1  46.699997   \n",
       "1          1           1            1  Japanese         0       1  46.699997   \n",
       "2          1           1            1  European         0       1  46.699997   \n",
       "3          1           1            1    Korean         0       1  46.699997   \n",
       "4          2           2            2  American         1       1  26.100000   \n",
       "\n",
       "   speed  discount  price  \n",
       "0     10      0.94     90  \n",
       "1      8      0.94    110  \n",
       "2      7      0.94     50  \n",
       "3      8      0.94     10  \n",
       "4     10      0.95    100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You could download the data from our Github repository and load it using the following code.\n",
    "# https://raw.githubusercontent.com/gsbDBI/torch-choice/main/tutorials/public_datasets/car_choice.csv\n",
    "car_choice = pd.read_csv(\"./torch_choice_paper_data/car_choice.csv\")\n",
    "car_choice.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Observables, Method 1: Observables Derived from Columns of the Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating choice dataset from stata format data-frames...\n",
      "Note: choice sets of different sizes found in different purchase records: {'size 4': 'occurrence 505', 'size 3': 'occurrence 380'}\n",
      "Finished Creating Choice Dataset.\n",
      "* purchase record index range: [1 2 3] ... [883 884 885]\n",
      "* Space of 4 items:\n",
      "                   0         1         2       3\n",
      "item name  American  European  Japanese  Korean\n",
      "* Number of purchase records/cases: 885.\n",
      "* Preview of main data frame:\n",
      "      record_id  session_id  consumer_id       car  purchase  gender  \\\n",
      "0             1           1            1  American         1       1   \n",
      "1             1           1            1  Japanese         0       1   \n",
      "2             1           1            1  European         0       1   \n",
      "3             1           1            1    Korean         0       1   \n",
      "4             2           2            2  American         1       1   \n",
      "...         ...         ...          ...       ...       ...     ...   \n",
      "3155        884         884          884  Japanese         1       1   \n",
      "3156        884         884          884  European         0       1   \n",
      "3157        885         885          885  American         1       1   \n",
      "3158        885         885          885  Japanese         0       1   \n",
      "3159        885         885          885  European         0       1   \n",
      "\n",
      "         income  speed  discount  price  \n",
      "0     46.699997     10      0.94     90  \n",
      "1     46.699997      8      0.94    110  \n",
      "2     46.699997      7      0.94     50  \n",
      "3     46.699997      8      0.94     10  \n",
      "4     26.100000     10      0.95    100  \n",
      "...         ...    ...       ...    ...  \n",
      "3155  20.900000      8      0.89    100  \n",
      "3156  20.900000      7      0.89     40  \n",
      "3157  30.600000     10      0.81    100  \n",
      "3158  30.600000      8      0.81     50  \n",
      "3159  30.600000      7      0.81     40  \n",
      "\n",
      "[3160 rows x 10 columns]\n",
      "* Preview of ChoiceDataset:\n",
      "ChoiceDataset(num_items=4, num_users=885, num_sessions=885, label=[], item_index=[885], user_index=[885], session_index=[885], item_availability=[885, 4], item_speed=[4, 1], user_gender=[885, 1], user_income=[885, 1], session_discount=[885, 1], itemsession_price=[885, 4, 1], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "user_observable_columns=[\"gender\", \"income\"]\n",
    "from torch_choice.utils.easy_data_wrapper import EasyDatasetWrapper\n",
    "data_wrapper_from_columns = EasyDatasetWrapper(\n",
    "    main_data=car_choice,\n",
    "    purchase_record_column='record_id',\n",
    "    choice_column='purchase',\n",
    "    item_name_column='car',\n",
    "    user_index_column='consumer_id',\n",
    "    session_index_column='session_id',\n",
    "    user_observable_columns=['gender', 'income'],\n",
    "    item_observable_columns=['speed'],\n",
    "    session_observable_columns=['discount'],\n",
    "    itemsession_observable_columns=['price'])\n",
    "\n",
    "data_wrapper_from_columns.summary()\n",
    "dataset = data_wrapper_from_columns.choice_dataset\n",
    "# ChoiceDataset(label=[], item_index=[885], provided_num_items=[], user_index=[885], session_index=[885], item_availability=[885, 4], item_speed=[4, 1], user_gender=[885, 1], user_income=[885, 1], session_discount=[885, 1], itemsession_price=[885, 4, 1], device=cpu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Observables, Method 2: Added as Separated DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes for gender and income. The dataframe for user-specific observable needs to have the `consumer_id` column.\n",
    "gender = car_choice.groupby('consumer_id')['gender'].first().reset_index()\n",
    "income = car_choice.groupby('consumer_id')['income'].first().reset_index()\n",
    "# alternatively, put gender and income in the same dataframe.\n",
    "gender_and_income = car_choice.groupby('consumer_id')[['gender', 'income']].first().reset_index()\n",
    "# speed as item observable, the dataframe requires a `car` column.\n",
    "speed = car_choice.groupby('car')['speed'].first().reset_index()\n",
    "# discount as session observable. the dataframe requires a `session_id` column.\n",
    "discount = car_choice.groupby('session_id')['discount'].first().reset_index()\n",
    "# create the price as itemsession observable, the dataframe requires both `car` and `session_id` columns.\n",
    "price = car_choice[['car', 'session_id', 'price']]\n",
    "# fill in NANs for (session, item) pairs that the item was not available in that session.\n",
    "price = price.pivot('car', 'session_id', 'price').melt(ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating choice dataset from stata format data-frames...\n",
      "Note: choice sets of different sizes found in different purchase records: {'size 4': 'occurrence 505', 'size 3': 'occurrence 380'}\n",
      "Finished Creating Choice Dataset.\n"
     ]
    }
   ],
   "source": [
    "data_wrapper_from_dataframes = EasyDatasetWrapper(\n",
    "    main_data=car_choice,\n",
    "    purchase_record_column='record_id',\n",
    "    choice_column='purchase',\n",
    "    item_name_column='car',\n",
    "    user_index_column='consumer_id',\n",
    "    session_index_column='session_id',\n",
    "    user_observable_data={'gender': gender, 'income': income},\n",
    "    # alternatively, supply gender and income as a single dataframe.\n",
    "    # user_observable_data={'gender_and_income': gender_and_income},\n",
    "    item_observable_data={'speed': speed},\n",
    "    session_observable_data={'discount': discount},\n",
    "    itemsession_observable_data={'price': price})\n",
    "\n",
    "# the second method creates exactly the same ChoiceDataset as the previous method.\n",
    "assert data_wrapper_from_dataframes.choice_dataset == data_wrapper_from_columns.choice_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating choice dataset from stata format data-frames...\n",
      "Note: choice sets of different sizes found in different purchase records: {'size 4': 'occurrence 505', 'size 3': 'occurrence 380'}\n",
      "Finished Creating Choice Dataset.\n"
     ]
    }
   ],
   "source": [
    "data_wrapper_mixed = EasyDatasetWrapper(\n",
    "    main_data=car_choice,\n",
    "    purchase_record_column='record_id',\n",
    "    choice_column='purchase',\n",
    "    item_name_column='car',\n",
    "    user_index_column='consumer_id',\n",
    "    session_index_column='session_id',\n",
    "    user_observable_data={'gender': gender, 'income': income},\n",
    "    item_observable_data={'speed': speed},\n",
    "    session_observable_data={'discount': discount},\n",
    "    itemsession_observable_columns=['price'])\n",
    "\n",
    "# these methods create exactly the same choice dataset.\n",
    "assert data_wrapper_mixed.choice_dataset == data_wrapper_from_columns.choice_dataset == data_wrapper_from_dataframes.choice_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Choice Dataset, Method 2: Building from Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10_000\n",
    "num_users = 10\n",
    "num_items = 4\n",
    "num_sessions = 500\n",
    "\n",
    "\n",
    "user_obs = torch.randn(num_users, 128)\n",
    "item_obs = torch.randn(num_items, 64)\n",
    "useritem_obs = torch.randn(num_users, num_items, 32)\n",
    "session_obs = torch.randn(num_sessions, 10)\n",
    "itemsession_obs = torch.randn(num_sessions, num_items, 12)\n",
    "usersession_obs = torch.randn(num_users, num_sessions, 10)\n",
    "usersessionitem_obs = torch.randn(num_users, num_sessions, num_items, 8)\n",
    "\n",
    "item_index = torch.LongTensor(np.random.choice(num_items, size=N))\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=N))\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=N))\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()\n",
    "\n",
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    item_index=item_index,  # required.\n",
    "    num_items=num_items,\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    num_users=num_users,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    itemsession_obs=itemsession_obs,\n",
    "    useritem_obs=useritem_obs,\n",
    "    usersession_obs=usersession_obs,\n",
    "    usersessionitem_obs=usersessionitem_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDataset(num_items=4, num_users=10, num_sessions=500, label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 32], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities of the Choice Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.num_users=10\n",
      "dataset.num_items=4\n",
      "dataset.num_sessions=500\n",
      "len(dataset)=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'{dataset.num_users=:}')\n",
    "# dataset.num_users=10\n",
    "print(f'{dataset.num_items=:}')\n",
    "# dataset.num_items=4\n",
    "print(f'{dataset.num_sessions=:}')\n",
    "# dataset.num_sessions=500\n",
    "print(f'{len(dataset)=:}')\n",
    "# len(dataset)=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 0, 2, 2, 3, 0, 0, 2, 1])\n",
      "tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.])\n",
      "tensor([2, 3, 0, 2, 2, 3, 0, 0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# clone\n",
    "print(dataset.item_index[:10])\n",
    "# tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1])\n",
    "dataset_cloned = dataset.clone()\n",
    "# modify the cloned dataset.\n",
    "dataset_cloned.item_index = 99 * torch.ones(num_sessions)\n",
    "print(dataset_cloned.item_index[:10])\n",
    "# the cloned dataset is changed.\n",
    "# tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.])\n",
    "print(dataset.item_index[:10])\n",
    "# the original dataset does not change.\n",
    "# tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.device=cpu\n",
      "dataset.device=cpu\n",
      "dataset.user_index.device=cpu\n",
      "dataset.session_index.device=cpu\n",
      "dataset.device=cuda:0\n",
      "dataset.item_index.device=cuda:0\n",
      "dataset.user_index.device=cuda:0\n",
      "dataset.session_index.device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# move to device\n",
    "print(f'{dataset.device=:}')\n",
    "# dataset.device=cpu\n",
    "print(f'{dataset.device=:}')\n",
    "# dataset.device=cpu\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "# dataset.user_index.device=cpu\n",
    "print(f'{dataset.session_index.device=:}')\n",
    "# dataset.session_index.device=cpu\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # please note that this can only be demonstrated\n",
    "    dataset = dataset.to('cuda')\n",
    "\n",
    "    print(f'{dataset.device=:}')\n",
    "    # dataset.device=cuda:0\n",
    "    print(f'{dataset.item_index.device=:}')\n",
    "    # dataset.item_index.device=cuda:0\n",
    "    print(f'{dataset.user_index.device=:}')\n",
    "    # dataset.user_index.device=cuda:0\n",
    "    print(f'{dataset.session_index.device=:}')\n",
    "    # dataset.session_index.device=cuda:0\n",
    "\n",
    "    dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.itemsession_obs.shape=torch.Size([10000, 4, 12])\n",
      "dict.useritem_obs.shape=torch.Size([10000, 4, 32])\n",
      "dict.usersession_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.usersessionitem_obs.shape=torch.Size([10000, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "def print_dict_shape(d):\n",
    "    for key, val in d.items():\n",
    "        if torch.is_tensor(val):\n",
    "            print(f'dict.{key}.shape={val.shape}')\n",
    "print_dict_shape(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7119, 9650, 5466, 1073, 8419])\n",
      "ChoiceDataset(num_items=4, num_users=10, num_sessions=500, label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 32], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      "ChoiceDataset(num_items=4, num_users=10, num_sessions=500, label=[], item_index=[5], user_index=[5], session_index=[5], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 32], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "# __getitem__ to get batch.\n",
    "# pick 5 random sessions as the mini-batch.\n",
    "dataset = dataset.to('cpu')\n",
    "indices = torch.Tensor(np.random.choice(len(dataset), size=5, replace=False)).long()\n",
    "print(indices)\n",
    "# tensor([1118,  976, 1956,  290, 8283])\n",
    "subset = dataset[indices]\n",
    "print(dataset)\n",
    "# ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
    "print(subset)\n",
    "# ChoiceDataset(label=[], item_index=[5], user_index=[5], session_index=[5], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1, 2, 3])\n",
      "tensor([2, 2, 1, 2, 3])\n",
      "tensor([3, 3, 2, 3, 4])\n",
      "tensor([2, 2, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(subset.item_index)\n",
    "# tensor([0, 1, 0, 0, 0])\n",
    "print(dataset.item_index[indices])\n",
    "# tensor([0, 1, 0, 0, 0])\n",
    "\n",
    "subset.item_index += 1  # modifying the batch does not change the original dataset.\n",
    "\n",
    "print(subset.item_index)\n",
    "# tensor([1, 2, 1, 1, 1])\n",
    "print(dataset.item_index[indices])\n",
    "# tensor([0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2949)\n",
      "tensor(-0.2949)\n",
      "tensor(0.7051)\n",
      "tensor(-0.2949)\n"
     ]
    }
   ],
   "source": [
    "print(subset.item_obs[0, 0])\n",
    "# tensor(-1.5811)\n",
    "print(dataset.item_obs[0, 0])\n",
    "# tensor(-1.5811)\n",
    "\n",
    "subset.item_obs += 1\n",
    "print(subset.item_obs[0, 0])\n",
    "# tensor(-0.5811)\n",
    "print(dataset.item_obs[0, 0])\n",
    "# tensor(-1.5811)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139976280433184\n",
      "139975728990704\n"
     ]
    }
   ],
   "source": [
    "print(id(subset.item_index))\n",
    "# 140339656298640\n",
    "print(id(dataset.item_index[indices]))\n",
    "# 140339656150528\n",
    "# these two are different objects in memory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Multiple Datasets with JointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointDataset with 2 sub-datasets: (\n",
      "\titem: ChoiceDataset(num_items=4, num_users=10, num_sessions=500, label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 32], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      "\tnest: ChoiceDataset(num_items=4, num_users=10, num_sessions=500, label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], itemsession_obs=[500, 4, 12], useritem_obs=[10, 4, 32], usersession_obs=[10, 500, 10], usersessionitem_obs=[10, 500, 4, 8], device=cpu)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "item_level_dataset = dataset.clone()\n",
    "nest_level_dataset = dataset.clone()\n",
    "joint_dataset = JointDataset(\n",
    "    item=item_level_dataset,\n",
    "    nest=nest_level_dataset)\n",
    "\n",
    "print(joint_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler, SequentialSampler, RandomSampler\n",
    "shuffle = False  # for demonstration purpose.\n",
    "batch_size = 32\n",
    "\n",
    "# Create sampler.\n",
    "sampler = BatchSampler(\n",
    "    RandomSampler(dataset) if shuffle else SequentialSampler(dataset),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         sampler=sampler,\n",
    "                                         collate_fn=lambda x: x[0],\n",
    "                                         pin_memory=(dataset.device == 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_obs.shape=torch.Size([4, 64])\n",
      "item_obs_all.shape=torch.Size([10000, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'{item_obs.shape=:}')\n",
    "# item_obs.shape=torch.Size([4, 64])\n",
    "item_obs_all = item_obs.view(1, num_items, -1).expand(len(dataset), -1, -1)\n",
    "item_obs_all = item_obs_all.to(dataset.device)\n",
    "item_index_all = item_index.to(dataset.device)\n",
    "print(f'{item_obs_all.shape=:}')\n",
    "# item_obs_all.shape=torch.Size([10000, 4, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    first, last = i * batch_size, min(len(dataset), (i + 1) * batch_size)\n",
    "    idx = torch.arange(first, last)\n",
    "    assert torch.all(item_obs_all[idx, :, :] == batch.x_dict['item_obs'])\n",
    "    assert torch.all(item_index_all[idx] == batch.item_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x_dict['item_obs'].shape\n",
    "# torch.Size([16, 4, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.itemsession_obs.shape=torch.Size([10000, 4, 12])\n",
      "dict.useritem_obs.shape=torch.Size([10000, 4, 32])\n",
      "dict.usersession_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.usersessionitem_obs.shape=torch.Size([10000, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print_dict_shape(dataset.x_dict)\n",
    "# dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
    "# dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
    "# dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
    "# dict.price_obs.shape=torch.Size([10000, 4, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()\n",
    "# 10000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Logit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_mode_canada_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDataset(num_items=4, num_users=1, num_sessions=2779, label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], itemsession_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], itemsession_ivt=[2779, 4, 1], device=cpu)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalLogitModel(\n",
    "    formula='(itemsession_cost_freq_ovt|constant) + (session_income|item) + (itemsession_ivt|item-full) + (intercept|item)',\n",
    "    dataset=dataset,\n",
    "    num_items=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalLogitModel(\n",
    "    coef_variation_dict={'itemsession_cost_freq_ovt': 'constant',\n",
    "                         'session_income': 'item',\n",
    "                         'itemsession_ivt': 'item-full',\n",
    "                         'intercept': 'item'},\n",
    "    num_param_dict={'itemsession_cost_freq_ovt': 3,\n",
    "                    'session_income': 1,\n",
    "                    'itemsession_ivt': 1,\n",
    "                    'intercept': 1},\n",
    "    num_items=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalLogitModel(\n",
    "    coef_variation_dict={'itemsession_cost_freq_ovt': 'constant',\n",
    "                         'session_income': 'item',\n",
    "                         'itemsession_ivt': 'item-full',\n",
    "                         'intercept': 'item'},\n",
    "    num_param_dict={'itemsession_cost_freq_ovt': 3,\n",
    "                    'session_income': 1,\n",
    "                    'itemsession_ivt': 1,\n",
    "                    'intercept': 1},\n",
    "    num_items=4,\n",
    "    regularization=\"L1\", regularization_weight=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | ConditionalLogitModel | 13    \n",
      "------------------------------------------------\n",
      "13        Trainable params\n",
      "0         Non-trainable params\n",
      "13        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (itemsession_cost_freq_ovt[constant]): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
      "    (session_income[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
      "    (itemsession_ivt[item-full]): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, initialization=normal, device=cpu).\n",
      "    (intercept[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[itemsession_cost_freq_ovt[constant]] with 3 parameters, with constant level variation.\n",
      "X[session_income[item]] with 1 parameters, with item level variation.\n",
      "X[itemsession_ivt[item-full]] with 1 parameters, with item-full level variation.\n",
      "X[intercept[item]] with 1 parameters, with item level variation.\n",
      "device=cpu\n",
      "==================== data set received ====================\n",
      "[Train dataset] ChoiceDataset(num_items=4, num_users=1, num_sessions=2779, label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], itemsession_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], itemsession_ivt=[2779, 4, 1], device=cpu)\n",
      "[Validation dataset] None\n",
      "[Test dataset] None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d7342200934728898d33648237fb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training: 19.963228940963745\n",
      "Skip testing, no test dataset is provided.\n",
      "==================== model results ====================\n",
      "Log-likelihood: [Training] -1874.63818359375, [Validation] N/A, [Test] N/A\n",
      "\n",
      "| Coefficient                           |   Estimation |   Std. Err. |       z-value |    Pr(>|z|) | Significance   |\n",
      "|:--------------------------------------|-------------:|------------:|--------------:|------------:|:---------------|\n",
      "| itemsession_cost_freq_ovt[constant]_0 | -0.0372948   |  0.0070951  |  -5.25641     | 1.46897e-07 | ***            |\n",
      "| itemsession_cost_freq_ovt[constant]_1 |  0.0934485   |  0.00509611 |  18.3372      | 0           | ***            |\n",
      "| itemsession_cost_freq_ovt[constant]_2 | -0.042776    |  0.00322201 | -13.2762      | 0           | ***            |\n",
      "| session_income[item]_0                | -0.0862387   |  0.018302   |  -4.71199     | 2.45312e-06 | ***            |\n",
      "| session_income[item]_1                | -0.0269129   |  0.00384875 |  -6.99265     | 2.69762e-12 | ***            |\n",
      "| session_income[item]_2                | -0.0370588   |  0.00406316 |  -9.12068     | 0           | ***            |\n",
      "| itemsession_ivt[item-full]_0          |  0.059378    |  0.0100868  |   5.88671     | 3.93962e-09 | ***            |\n",
      "| itemsession_ivt[item-full]_1          | -0.00634744  |  0.00428099 |  -1.4827      | 0.138153    |                |\n",
      "| itemsession_ivt[item-full]_2          | -0.00583245  |  0.00189436 |  -3.07885     | 0.00207804  | **             |\n",
      "| itemsession_ivt[item-full]_3          | -0.00137824  |  0.00118698 |  -1.16113     | 0.245588    |                |\n",
      "| intercept[item]_0                     |  3.91833e-09 |  1.26826    |   3.08953e-09 | 1           |                |\n",
      "| intercept[item]_1                     |  1.32592     |  0.703733   |   1.88412     | 0.0595492   |                |\n",
      "| intercept[item]_2                     |  2.81914     |  0.618203   |   4.56021     | 5.11019e-06 | ***            |\n",
      "Significance codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConditionalLogitModel(\n",
       "  (coef_dict): ModuleDict(\n",
       "    (itemsession_cost_freq_ovt[constant]): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
       "    (session_income[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
       "    (itemsession_ivt[item-full]): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, initialization=normal, device=cpu).\n",
       "    (intercept[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, initialization=normal, device=cpu).\n",
       "  )\n",
       ")\n",
       "Conditional logistic discrete choice model, expects input features:\n",
       "\n",
       "X[itemsession_cost_freq_ovt[constant]] with 3 parameters, with constant level variation.\n",
       "X[session_income[item]] with 1 parameters, with item level variation.\n",
       "X[itemsession_ivt[item-full]] with 1 parameters, with item-full level variation.\n",
       "X[intercept[item]] with 1 parameters, with item level variation.\n",
       "device=cpu"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_choice import run\n",
    "run(model, dataset, batch_size=-1, learning_rate=0.01, num_epochs=1000, model_optimizer=\"LBFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# You can visualize the training process using TensorBoard by (1) running the following command in terminal and (2) opening the browser and navigating to http://localhost:6006.\n",
    "! tensorboard --logdir ./lightning_logs --port 6006"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Logit Model\n",
    "Our paper provided an overview of the nested logit model API without concrete examples or executable code. For a complete example of the nested logit model, please refer to the nested-logit model tutorial for executable code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
