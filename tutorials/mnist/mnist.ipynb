{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `torch-choice` as Benchmark Model in Machine Learning Setting: MNIST Dataset\n",
    "\n",
    "This tutorial demonstrate the usage of `torch-choice`'s logit model as a benchmark multinominal model in machine learning setting. We will use the MNIST dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch, torchvision\n",
    "\n",
    "from torch_choice.data import ChoiceDataset\n",
    "from torch_choice.model import ConditionalLogitModel\n",
    "from torch_choice import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.0+cu117\n",
      "GPU Available:  True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"GPU Available: \",torch.cuda.is_available())\n",
    "# use GPU is available else use CPU.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset.\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.data.shape=torch.Size([60000, 28, 28])\n",
      "mnist_train.targets.shape=torch.Size([60000])\n",
      "mnist_test.data.shape=torch.Size([10000, 28, 28])\n",
      "mnist_test.targets.shape=torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(f'{mnist_train.data.shape=:}')\n",
    "print(f'{mnist_train.targets.shape=:}')\n",
    "print(f'{mnist_test.data.shape=:}')\n",
    "print(f'{mnist_test.targets.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=torch.Size([70000, 784])\n",
      "y.shape=torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "X = torch.cat([mnist_train.data.reshape(60000, -1), mnist_test.data.reshape(10000, -1)], dim=0)\n",
    "y = torch.cat([mnist_train.targets, mnist_test.targets], dim=0)\n",
    "print(f'{X.shape=:}')\n",
    "print(f'{y.shape=:}')\n",
    "N_train = 60000\n",
    "N_test = 10000\n",
    "N = N_train + N_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume each image in the MNIST dataset is corresponding to a session, and we are predicting the \"item\" chosen in this session. The chosen \"item\" is the digit in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(session_index=torch.arange(N), item_index=y, session_image=X)\n",
    "train_index = torch.arange(60000)\n",
    "test_index = torch.arange(60000, 60000 + 10000)\n",
    "# we don't have a validation set.\n",
    "dataset_train = dataset[train_index].to(DEVICE)\n",
    "dataset_test = dataset[test_index].to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each digit $i \\in \\{0, 1, \\dots 9\\}$, for each image indexed $n \\in \\{1, 2, \\dots, 70000\\}$, let $X^{(n)} \\in \\mathbb{R}^{768}$ denote image $n$'s feature vector. The potential of image $n$ to represent digit $i$ is captured by:\n",
    "$$\n",
    "U_{i}^{(n)} = \\alpha_i + (X^{(n)})^T \\beta_i\n",
    "$$\n",
    "\n",
    "The predicted probability of image $n$ being digit $i$ is given by the soft-max transformation of above potentials:\n",
    "\n",
    "$$\n",
    "P_{i}^{(n)} = \\frac{\\exp(U_{i}^{(n)})}{\\sum_{j=0}^9 \\exp(U_{j}^{(n)})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalLogitModel(\n",
    "    formula='(session_image|item-full) + (1|item-full)',\n",
    "    dataset=dataset_train,\n",
    "    num_items=10)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/tianyudu/anaconda3/envs/dev/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | ConditionalLogitModel | 7.9 K \n",
      "------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (session_image[item-full]): Coefficient(variation=item-full, num_items=10, num_users=None, num_params=784, 7840 trainable parameters in total, device=cuda:0).\n",
      "    (intercept[item-full]): Coefficient(variation=item-full, num_items=10, num_users=None, num_params=1, 10 trainable parameters in total, device=cuda:0).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[session_image[item-full]] with 784 parameters, with item-full level variation.\n",
      "X[intercept[item-full]] with 1 parameters, with item-full level variation.\n",
      "device=cuda:0\n",
      "==================== data set received ====================\n",
      "[Train dataset] ChoiceDataset(label=[], item_index=[60000], user_index=[], session_index=[60000], item_availability=[], session_image=[70000, 784], device=cuda:0)\n",
      "[Validation dataset] None\n",
      "[Test dataset] ChoiceDataset(label=[], item_index=[10000], user_index=[], session_index=[10000], item_availability=[], session_image=[70000, 784], device=cuda:0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyudu/anaconda3/envs/dev/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/tianyudu/anaconda3/envs/dev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=3). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1456a7af85424fafbe6e0db9604821a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training: 113.30555725097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyudu/anaconda3/envs/dev/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff84ca59bc24f80830d2cd8e11e0df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_log_likelihood    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -3687.095947265625     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_log_likelihood   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -3687.095947265625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 113.3552496433258\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "run(model, dataset_train=dataset_train, dataset_test=dataset_test, num_epochs=300, learning_rate=0.003, model_optimizer=\"LBFGS\", batch_size=-1, device=DEVICE, report_std=False)\n",
    "print('Time taken:', time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 94.33%.\n",
      "Test Accuracy: 91.95%.\n"
     ]
    }
   ],
   "source": [
    "train_acc = torch.mean((model.forward(dataset_train).argmax(dim=1) == dataset_train.item_index).float())\n",
    "test_acc = torch.mean((model.forward(dataset_test).argmax(dim=1) == dataset_test.item_index).float())\n",
    "print(f\"Training Accuracy: {train_acc*100:.2f}%.\")\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
