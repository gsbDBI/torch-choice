{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Utility Model (RUM) Part II: Nested Logit Model\n",
    "Author: Tianyu Du\n",
    "\n",
    "The package implements the nested logit model as well, which allows researchers to model choices as a two-stage process: the user first picks a category of purchase and then picks the item from the chosen category that generates the most utility.\n",
    "\n",
    "Examples here are modified from [Exercise 2: Nested logit model by Kenneth Train and Yves Croissant](https://cran.r-project.org/web/packages/mlogit/vignettes/e2nlogit.html)\n",
    "The data set HC from mlogit contains data in R format on the choice of heating and central cooling system for 250 single-family, newly built houses in California.\n",
    "\n",
    "\n",
    "The alternatives are:\n",
    "\n",
    "- Gas central heat with cooling gcc,\n",
    "- Electric central resistence heat with cooling ecc,\n",
    "- Electric room resistence heat with cooling erc,\n",
    "- Electric heat pump, which provides cooling also hpc,\n",
    "- Gas central heat without cooling gc,\n",
    "- Electric central resistence heat without cooling ec,\n",
    "- Electric room resistence heat without cooling er.\n",
    "- Heat pumps necessarily provide both heating and cooling such that heat pump without cooling is not an alternative.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "- depvar gives the name of the chosen alternative,\n",
    "- ich.alt are the installation cost for the heating portion of the system,\n",
    "- icca is the installation cost for cooling\n",
    "- och.alt are the operating cost for the heating portion of the system\n",
    "- occa is the operating cost for cooling\n",
    "- income is the annual income of the household\n",
    "\n",
    "Note that the full installation cost of alternative gcc is ich.gcc+icca, and similarly for the operating cost and for the other alternatives with cooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Logit Model: Background\n",
    "The following code block provides an example initialization of the `NestedLogitModel` (please refer to examples below for details).\n",
    "```python\n",
    "model = NestedLogitModel(category_to_item=category_to_item,\n",
    "                         category_coef_variation_dict={},\n",
    "                         category_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "```\n",
    "\n",
    "The nested logit model decompose the utility of choosing item $i$ into the (1) item-specific values and (2) category specify values.  For simplicity, suppose item $i$  belongs to category $k \\in \\{1, \\dots, K\\}$: $i \\in B_k$.\n",
    "$$\n",
    "U_{uit} = W_{ukt} + Y_{uit}\n",
    "$$\n",
    "Where both $W$ and $Y$ are estimated using linear models from as in the conditional logit model.\n",
    "\n",
    "The log-likelihood for user $u$ to choose item $i$ at time/session $t$ decomposes into the item-level likelihood and category-level likelihood.\n",
    "$$\n",
    "\\log P(i \\mid u, t) = \\log P(i \\mid u, t, B_k) + \\log P(k \\mid u, t) \\\\\n",
    "= \\log \\left(\\frac{\\exp(Y_{uit}/\\lambda_k)}{\\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)}\\right) + \\log \\left( \\frac{\\exp(W_{ukt} + \\lambda_k I_{ukt})}{\\sum_{\\ell=1}^K \\exp(W_{u\\ell t} + \\lambda_\\ell I_{u\\ell t})}\\right)\n",
    "$$\n",
    "The **inclusive value** of category $k$, $I_{ukt}$ is defined as $\\log \\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)$, which is the *expected utility from choosing the best alternative from category $k$*.\n",
    "\n",
    "The `category_to_item` keyword defines a dictionary of the mapping $k \\mapsto B_k$, where keys of `category_to_item`  are integer $k$'s and  `category_to_item[k]`  is a list consisting of IDs of items in $B_k$.\n",
    "\n",
    "The `{category, item}_coef_variation_dict` provides specification to $W_{ukt}$ and $Y_{uit}$ respectively, `torch_choice` allows for empty category level models by providing an empty dictionary (in this case, $W_{ukt} = \\epsilon_{ukt}$) since the inclusive value term $\\lambda_k I_{ukt}$ will be used to model the choice over categories. However, by specifying an empty second stage model ($Y_{uit} = \\epsilon_{uit}$), the nested logit model reduces to a conditional logit model of choices over categories. Hence, one should never use the `NestedLogitModel` class with an empty item-level model.\n",
    "\n",
    "Similar to the conditional logit model, `{category, item}_num_param_dict` specify the dimension (number of observables to be multiplied with the coefficient) of coefficients. The above code initializes a simple model built upon item-time-specific observables $X_{it} \\in \\mathbb{R}^7$,\n",
    "$$\n",
    "Y_{uit} = \\beta^\\top X_{it} + \\epsilon_{uit} \\\\\n",
    "W_{ukt} = \\epsilon_{ukt}\n",
    "$$\n",
    "The research may wish to enfoce the *elasiticity* $\\lambda_k$ to be constant across categories, setting `shared_lambda=True` enforces $\\lambda_k = \\lambda\\ \\forall k \\in [K]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Essential Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device used: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch_choice.data import ChoiceDataset, JointDataset, utils\n",
    "from torch_choice.model.nested_logit_model import NestedLogitModel\n",
    "from torch_choice.utils.run_helper import run\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA device used: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encompass Configurations in a Name Space Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(data_path='./',\n",
    "                          batch_size=-1,  # full-batch.\n",
    "                          shuffle=False,\n",
    "                          num_epochs=30000,\n",
    "                          device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depvar</th>\n",
       "      <th>icca</th>\n",
       "      <th>occa</th>\n",
       "      <th>income</th>\n",
       "      <th>ich</th>\n",
       "      <th>och</th>\n",
       "      <th>idx.id1</th>\n",
       "      <th>idx.id2</th>\n",
       "      <th>inc.room</th>\n",
       "      <th>inc.cooling</th>\n",
       "      <th>int.cooling</th>\n",
       "      <th>cooling.modes</th>\n",
       "      <th>room.modes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>24.50</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1</td>\n",
       "      <td>ec</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>27.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>20</td>\n",
       "      <td>7.86</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1</td>\n",
       "      <td>ecc</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>7.37</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>er</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>27.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>20</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>erc</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>24.08</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1</td>\n",
       "      <td>gc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depvar   icca  occa  income    ich   och  idx.id1 idx.id2  inc.room  \\\n",
       "0   False   0.00  0.00      20  24.50  4.09        1      ec         0   \n",
       "1   False  27.28  2.95      20   7.86  4.09        1     ecc         0   \n",
       "2   False   0.00  0.00      20   7.37  3.85        1      er        20   \n",
       "3    True  27.28  2.95      20   8.79  3.85        1     erc        20   \n",
       "4   False   0.00  0.00      20  24.08  2.26        1      gc         0   \n",
       "\n",
       "   inc.cooling  int.cooling  cooling.modes  room.modes  \n",
       "0            0            0          False       False  \n",
       "1           20            1           True       False  \n",
       "2            0            0          False        True  \n",
       "3           20            1           True        True  \n",
       "4            0            0          False       False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./public_datasets/HC.csv', index_col=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was actually chosen.\n",
    "item_index = df[df['depvar'] == True].sort_values(by='idx.id1')['idx.id2'].reset_index(drop=True)\n",
    "item_names = ['ec', 'ecc', 'er', 'erc', 'gc', 'gcc', 'hpc']\n",
    "num_items = df['idx.id2'].nunique()\n",
    "# cardinal encoder.\n",
    "encoder = dict(zip(item_names, range(num_items)))\n",
    "item_index = item_index.map(lambda x: encoder[x])\n",
    "item_index = torch.LongTensor(item_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category feature: no category feature, all features are item-level.\n",
    "category_dataset = ChoiceDataset(item_index=item_index.clone()).to(args.device)\n",
    "\n",
    "# item feature.\n",
    "item_feat_cols = ['ich', 'och', 'icca', 'occa', 'inc.room', 'inc.cooling', 'int.cooling']\n",
    "price_obs = utils.pivot3d(df, dim0='idx.id1', dim1='idx.id2', values=item_feat_cols)\n",
    "item_dataset = ChoiceDataset(item_index=item_index, price_obs=price_obs).to(args.device)\n",
    "\n",
    "# combine dataets\n",
    "dataset = JointDataset(category=category_dataset, item=item_dataset)\n",
    "data_loader = utils.create_data_loader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "Run a nested logit model on the data for two nests and one log-sum coefficient that applies to both nests. Note that the model is specified to have the cooling alternatives `{gcc, ecc, erc, hpc}` in one nest and the non-cooling alternatives `{gc, ec, er}` in another nest.\n",
    "\n",
    "**NOTE**: We are computing the standard errors using $\\sqrt{\\text{diag}(H^{-1})}$, where $H$ is the\n",
    "hessian of negative log-likelihood with repsect to model parameters. This leads to slight different\n",
    "results compared with R implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_item = {0: ['gcc', 'ecc', 'erc', 'hpc'],\n",
    "                    1: ['gc', 'ec', 'er']}\n",
    "\n",
    "# convert names \n",
    "for k, v in category_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    category_to_item[k] = sorted(v)\n",
    "\n",
    "model = NestedLogitModel(category_to_item=category_to_item,\n",
    "                         category_coef_variation_dict={},\n",
    "                         category_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "NestedLogitModel(\n",
      "  (category_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
      "  )\n",
      ")\n",
      "==================== received dataset ====================\n",
      "JointDataset with 2 sub-datasets: (\n",
      "\tcategory: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0)\n",
      ")\n",
      "==================== training the model ====================\n",
      "Epoch 1000: Log-likelihood=-588.3027954101562\n",
      "Epoch 2000: Log-likelihood=-186.7021484375\n",
      "Epoch 3000: Log-likelihood=-179.2357635498047\n",
      "Epoch 4000: Log-likelihood=-178.38218688964844\n",
      "Epoch 5000: Log-likelihood=-178.31878662109375\n",
      "Epoch 6000: Log-likelihood=-178.27572631835938\n",
      "Epoch 7000: Log-likelihood=-178.22787475585938\n",
      "Epoch 8000: Log-likelihood=-178.18026733398438\n",
      "Epoch 9000: Log-likelihood=-178.14501953125\n",
      "Epoch 10000: Log-likelihood=-178.128662109375\n",
      "==================== model results ====================\n",
      "Training Epochs: 10000\n",
      "\n",
      "Learning Rate: 0.01\n",
      "\n",
      "Batch Size: 250 out of 250 observations in total\n",
      "\n",
      "Final Log-likelihood: -178.128662109375\n",
      "\n",
      "Coefficients:\n",
      "\n",
      "| Coefficient      |   Estimation |   Std. Err. |\n",
      "|:-----------------|-------------:|------------:|\n",
      "| lambda_weight_0  |     0.580075 |   0.165447  |\n",
      "| item_price_obs_0 |    -0.549378 |   0.143561  |\n",
      "| item_price_obs_1 |    -0.849512 |   0.235958  |\n",
      "| item_price_obs_2 |    -0.231246 |   0.110558  |\n",
      "| item_price_obs_3 |    -1.15354  |   1.03607   |\n",
      "| item_price_obs_4 |    -0.375084 |   0.0999644 |\n",
      "| item_price_obs_5 |     0.248696 |   0.0516442 |\n",
      "| item_price_obs_6 |    -5.57415  |   4.7879    |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (category_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset, num_epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Output\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(cooling = c(\"gcc\", \n",
    "##     \"ecc\", \"erc\", \"hpc\"), other = c(\"gc\", \"ec\", \"er\")), un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 11 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 7.26E-06 \n",
    "## successive function values within tolerance limits \n",
    "## \n",
    "## Coefficients :\n",
    "##              Estimate Std. Error z-value  Pr(>|z|)    \n",
    "## ich         -0.554878   0.144205 -3.8478 0.0001192 ***\n",
    "## och         -0.857886   0.255313 -3.3601 0.0007791 ***\n",
    "## icca        -0.225079   0.144423 -1.5585 0.1191212    \n",
    "## occa        -1.089458   1.219821 -0.8931 0.3717882    \n",
    "## inc.room    -0.378971   0.099631 -3.8038 0.0001425 ***\n",
    "## inc.cooling  0.249575   0.059213  4.2149 2.499e-05 ***\n",
    "## int.cooling -6.000415   5.562423 -1.0787 0.2807030    \n",
    "## iv           0.585922   0.179708  3.2604 0.0011125 ** \n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -178.12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "Re-estimate the model with the room alternatives in one nest and the central alternatives in another nest. (Note that a heat pump is a central system.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_item = {0: ['ec', 'ecc', 'gc', 'gcc', 'hpc'],\n",
    "                    1: ['er', 'erc']}\n",
    "for k, v in category_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    category_to_item[k] = sorted(v)\n",
    "\n",
    "model = NestedLogitModel(category_to_item=category_to_item,\n",
    "                            category_coef_variation_dict={},\n",
    "                            category_num_param_dict={},\n",
    "                        #  category_num_param_dict={'intercept': 1},\n",
    "                            item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                            item_num_param_dict={'price_obs': 7},\n",
    "                            shared_lambda=True\n",
    "                            )\n",
    "\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "NestedLogitModel(\n",
      "  (category_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
      "  )\n",
      ")\n",
      "==================== received dataset ====================\n",
      "JointDataset with 2 sub-datasets: (\n",
      "\tcategory: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0)\n",
      ")\n",
      "==================== training the model ====================\n",
      "Epoch 500: Log-likelihood=-182.41204833984375\n",
      "Epoch 1000: Log-likelihood=-180.3829803466797\n",
      "Epoch 1500: Log-likelihood=-180.6223907470703\n",
      "Epoch 2000: Log-likelihood=-180.298828125\n",
      "Epoch 2500: Log-likelihood=-180.500732421875\n",
      "Epoch 3000: Log-likelihood=-180.5670166015625\n",
      "Epoch 3500: Log-likelihood=-182.52322387695312\n",
      "Epoch 4000: Log-likelihood=-184.7764129638672\n",
      "Epoch 4500: Log-likelihood=-180.62258911132812\n",
      "Epoch 5000: Log-likelihood=-180.3092498779297\n",
      "==================== model results ====================\n",
      "Training Epochs: 5000\n",
      "\n",
      "Learning Rate: 0.3\n",
      "\n",
      "Batch Size: 250 out of 250 observations in total\n",
      "\n",
      "Final Log-likelihood: -180.3092498779297\n",
      "\n",
      "Coefficients:\n",
      "\n",
      "| Coefficient      |   Estimation |   Std. Err. |\n",
      "|:-----------------|-------------:|------------:|\n",
      "| lambda_weight_0  |     1.62779  |    0.664918 |\n",
      "| item_price_obs_0 |    -1.35793  |    0.530842 |\n",
      "| item_price_obs_1 |    -2.18411  |    0.886321 |\n",
      "| item_price_obs_2 |    -0.403624 |    0.237611 |\n",
      "| item_price_obs_3 |    -2.71561  |    2.08917  |\n",
      "| item_price_obs_4 |    -0.895584 |    0.337144 |\n",
      "| item_price_obs_5 |     0.495313 |    0.199812 |\n",
      "| item_price_obs_6 |   -16.0579   |    9.35129  |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (category_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset, num_epochs=5000, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Output\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(central = c(\"ec\", \n",
    "##     \"ecc\", \"gc\", \"gcc\", \"hpc\"), room = c(\"er\", \"erc\")), un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 10 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 5.87E-07 \n",
    "## gradient close to zero \n",
    "## \n",
    "## Coefficients :\n",
    "##              Estimate Std. Error z-value Pr(>|z|)  \n",
    "## ich          -1.13818    0.54216 -2.0993  0.03579 *\n",
    "## och          -1.82532    0.93228 -1.9579  0.05024 .\n",
    "## icca         -0.33746    0.26934 -1.2529  0.21024  \n",
    "## occa         -2.06328    1.89726 -1.0875  0.27681  \n",
    "## inc.room     -0.75722    0.34292 -2.2081  0.02723 *\n",
    "## inc.cooling   0.41689    0.20742  2.0099  0.04444 *\n",
    "## int.cooling -13.82487    7.94031 -1.7411  0.08167 .\n",
    "## iv            1.36201    0.65393  2.0828  0.03727 *\n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -180.02\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3\n",
    "Rewrite the code to allow three nests. For simplicity, estimate only one log-sum coefficient which is applied to all three nests. Estimate a model with alternatives gcc, ecc and erc in a nest, hpc in a nest alone, and alternatives gc, ec and er in a nest. Does this model seem better or worse than the model in exercise 1, which puts alternative hpc in the same nest as alternatives gcc, ecc and erc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_item = {0: ['gcc', 'ecc', 'erc'],\n",
    "                    1: ['hpc'],\n",
    "                    2: ['gc', 'ec', 'er']}\n",
    "for k, v in category_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    category_to_item[k] = sorted(v)\n",
    "\n",
    "model = NestedLogitModel(category_to_item=category_to_item,\n",
    "                         category_coef_variation_dict={},\n",
    "                         category_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True\n",
    "                         )\n",
    "\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "NestedLogitModel(\n",
      "  (category_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
      "  )\n",
      ")\n",
      "==================== received dataset ====================\n",
      "JointDataset with 2 sub-datasets: (\n",
      "\tcategory: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cuda:0)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cuda:0)\n",
      ")\n",
      "==================== training the model ====================\n",
      "Epoch 500: Log-likelihood=-254.35272216796875\n",
      "Epoch 1000: Log-likelihood=-199.40536499023438\n",
      "Epoch 1500: Log-likelihood=-193.3748321533203\n",
      "Epoch 2000: Log-likelihood=-187.37646484375\n",
      "Epoch 2500: Log-likelihood=-183.7972869873047\n",
      "Epoch 3000: Log-likelihood=-182.31369018554688\n",
      "Epoch 3500: Log-likelihood=-181.67796325683594\n",
      "Epoch 4000: Log-likelihood=-181.39984130859375\n",
      "Epoch 4500: Log-likelihood=-181.2567138671875\n",
      "Epoch 5000: Log-likelihood=-181.1448516845703\n",
      "==================== model results ====================\n",
      "Training Epochs: 5000\n",
      "\n",
      "Learning Rate: 0.01\n",
      "\n",
      "Batch Size: 250 out of 250 observations in total\n",
      "\n",
      "Final Log-likelihood: -181.1448516845703\n",
      "\n",
      "Coefficients:\n",
      "\n",
      "| Coefficient      |   Estimation |   Std. Err. |\n",
      "|:-----------------|-------------:|------------:|\n",
      "| lambda_weight_0  |     0.916814 |   0.189271  |\n",
      "| item_price_obs_0 |    -0.804039 |   0.0949913 |\n",
      "| item_price_obs_1 |    -1.29091  |   0.180003  |\n",
      "| item_price_obs_2 |    -0.382208 |   0.128881  |\n",
      "| item_price_obs_3 |    -2.60614  |   1.16214   |\n",
      "| item_price_obs_4 |    -0.543321 |   0.0711768 |\n",
      "| item_price_obs_5 |     0.310327 |   0.0555514 |\n",
      "| item_price_obs_6 |    -3.63363  |   4.96449   |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (category_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Output\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(n1 = c(\"gcc\", \n",
    "##     \"ecc\", \"erc\"), n2 = c(\"hpc\"), n3 = c(\"gc\", \"ec\", \"er\")), \n",
    "##     un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 8 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 3.71E-08 \n",
    "## gradient close to zero \n",
    "## \n",
    "## Coefficients :\n",
    "##               Estimate Std. Error z-value  Pr(>|z|)    \n",
    "## ich          -0.838394   0.100546 -8.3384 < 2.2e-16 ***\n",
    "## och          -1.331598   0.252069 -5.2827 1.273e-07 ***\n",
    "## icca         -0.256131   0.145564 -1.7596   0.07848 .  \n",
    "## occa         -1.405656   1.207281 -1.1643   0.24430    \n",
    "## inc.room     -0.571352   0.077950 -7.3297 2.307e-13 ***\n",
    "## inc.cooling   0.311355   0.056357  5.5247 3.301e-08 ***\n",
    "## int.cooling -10.413384   5.612445 -1.8554   0.06354 .  \n",
    "## iv            0.956544   0.180722  5.2929 1.204e-07 ***\n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -180.26\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7dc80b2c4d9dbaf52e273e24444ebf2c26f0fdc466c7e783c99ad3a1ce41bbd"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
