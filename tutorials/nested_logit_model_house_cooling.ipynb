{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Utility Model (RUM) Part II: Nested Logit Model\n",
    "Author: Tianyu Du\n",
    "\n",
    "The package implements the nested logit model as well, which allows researchers to model choices as a two-stage process: the user first picks a nest of purchase and then picks the item from the chosen nest that generates the most utility.\n",
    "\n",
    "Examples here are modified from [Exercise 2: Nested logit model by Kenneth Train and Yves Croissant](https://cran.r-project.org/web/packages/mlogit/vignettes/e2nlogit.html).\n",
    "\n",
    "The House Cooling (HC) dataset from `mlogit` contains data in R format on the choice of heating and central cooling system for 250 single-family, newly built houses in California.\n",
    "\n",
    "The dataset is small and serve as a demonstration of the nested logit model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The alternatives are:\n",
    "\n",
    "- Gas central heat with cooling `gcc`,\n",
    "- Electric central resistence heat with cooling `ecc`,\n",
    "- Electric room resistence heat with cooling `erc`,\n",
    "- Electric heat pump, which provides cooling also `hpc`,\n",
    "- Gas central heat without cooling `gc`,\n",
    "- Electric central resistence heat without cooling `ec`,\n",
    "- Electric room resistence heat without cooling `er`.\n",
    "- Heat pumps necessarily provide both heating and cooling such that heat pump without cooling is not an alternative.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "- `depvar` gives the name of the chosen alternative,\n",
    "- `ich.alt` are the installation cost for the heating portion of the system,\n",
    "- `icca` is the installation cost for cooling\n",
    "- `och.alt` are the operating cost for the heating portion of the system\n",
    "- `occa` is the operating cost for cooling\n",
    "- `income` is the annual income of the household\n",
    "\n",
    "Note that the full installation cost of alternative gcc is ich.gcc+icca, and similarly for the operating cost and for the other alternatives with cooling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Logit Model: Background\n",
    "The following code block provides an example initialization of the `NestedLogitModel` (please refer to examples below for details).\n",
    "```python\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_coef_variation_dict={},\n",
    "                         nest_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "```\n",
    "\n",
    "The nested logit model decompose the utility of choosing item $i$ into the (1) item-specific values and (2) nest specify values.  For simplicity, suppose item $i$  belongs to nest $k \\in \\{1, \\dots, K\\}$: $i \\in B_k$.\n",
    "\n",
    "$$\n",
    "U_{uit} = W_{ukt} + Y_{uit}\n",
    "$$\n",
    "\n",
    "Where both $W$ and $Y$ are estimated using linear models from as in the conditional logit model.\n",
    "\n",
    "The log-likelihood for user $u$ to choose item $i$ at time/session $t$ decomposes into the item-level likelihood and nest-level likelihood.\n",
    "\n",
    "$$\n",
    "\\log P(i \\mid u, t) = \\log P(i \\mid u, t, B_k) + \\log P(k \\mid u, t) \\\\\n",
    "= \\log \\left(\\frac{\\exp(Y_{uit}/\\lambda_k)}{\\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)}\\right) + \\log \\left( \\frac{\\exp(W_{ukt} + \\lambda_k I_{ukt})}{\\sum_{\\ell=1}^K \\exp(W_{u\\ell t} + \\lambda_\\ell I_{u\\ell t})}\\right)\n",
    "$$\n",
    "\n",
    "The **inclusive value** of nest $k$, $I_{ukt}$ is defined as $\\log \\sum_{j \\in B_k} \\exp(Y_{ujt}/\\lambda_k)$, which is the *expected utility from choosing the best alternative from nest $k$*.\n",
    "\n",
    "The `nest_to_item` keyword defines a dictionary of the mapping $k \\mapsto B_k$, where keys of `nest_to_item`  are integer $k$'s and  `nest_to_item[k]`  is a list consisting of IDs of items in $B_k$.\n",
    "\n",
    "The `{nest, item}_coef_variation_dict` provides specification to $W_{ukt}$ and $Y_{uit}$ respectively, `torch_choice` allows for empty nest level models by providing an empty dictionary (in this case, $W_{ukt} = \\epsilon_{ukt}$) since the inclusive value term $\\lambda_k I_{ukt}$ will be used to model the choice over nests. However, by specifying an empty second stage model ($Y_{uit} = \\epsilon_{uit}$), the nested logit model reduces to a conditional logit model of choices over nests. Hence, one should never use the `NestedLogitModel` class with an empty item-level model.\n",
    "\n",
    "Similar to the conditional logit model, `{nest, item}_num_param_dict` specify the dimension (number of observables to be multiplied with the coefficient) of coefficients. The above code initializes a simple model built upon item-time-specific observables $X_{it} \\in \\mathbb{R}^7$,\n",
    "\n",
    "$$\n",
    "Y_{uit} = \\beta^\\top X_{it} + \\epsilon_{uit} \\\\\n",
    "W_{ukt} = \\epsilon_{ukt}\n",
    "$$\n",
    "\n",
    "The research may wish to enfoce the *elasiticity* $\\lambda_k$ to be constant across nests, setting `shared_lambda=True` enforces $\\lambda_k = \\lambda\\ \\forall k \\in [K]$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Essential Packages\n",
    "We firstly read essential packages for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings for nicer outputs.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch_choice.data import ChoiceDataset, JointDataset, utils\n",
    "from torch_choice.model.nested_logit_model import NestedLogitModel\n",
    "from torch_choice import run\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select the appropriate device to run the model on, our package supports both CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tutorial on CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA device used: {torch.cuda.get_device_name()}')\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    print('Running tutorial on CPU')\n",
    "    DEVICE = 'cpu'\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "We firstly read the dataset for this tutorial, the `csv` file can be found at `./public_datasets/HC.csv`.\n",
    "Alternatively, we load the dataset directly from the Github website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depvar</th>\n",
       "      <th>icca</th>\n",
       "      <th>occa</th>\n",
       "      <th>income</th>\n",
       "      <th>ich</th>\n",
       "      <th>och</th>\n",
       "      <th>idx.id1</th>\n",
       "      <th>idx.id2</th>\n",
       "      <th>inc.room</th>\n",
       "      <th>inc.cooling</th>\n",
       "      <th>int.cooling</th>\n",
       "      <th>cooling.modes</th>\n",
       "      <th>room.modes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>24.50</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1</td>\n",
       "      <td>ec</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>27.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>20</td>\n",
       "      <td>7.86</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1</td>\n",
       "      <td>ecc</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>7.37</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>er</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>27.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>20</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>erc</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "      <td>24.08</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1</td>\n",
       "      <td>gc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depvar   icca  occa  income    ich   och  idx.id1 idx.id2  inc.room  \\\n",
       "0   False   0.00  0.00      20  24.50  4.09        1      ec         0   \n",
       "1   False  27.28  2.95      20   7.86  4.09        1     ecc         0   \n",
       "2   False   0.00  0.00      20   7.37  3.85        1      er        20   \n",
       "3    True  27.28  2.95      20   8.79  3.85        1     erc        20   \n",
       "4   False   0.00  0.00      20  24.08  2.26        1      gc         0   \n",
       "\n",
       "   inc.cooling  int.cooling  cooling.modes  room.modes  \n",
       "0            0            0          False       False  \n",
       "1           20            1           True       False  \n",
       "2            0            0          False        True  \n",
       "3           20            1           True        True  \n",
       "4            0            0          False       False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gsbDBI/torch-choice/main/tutorials/public_datasets/HC.csv', index_col=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset is in a long-format (i.e., each row contains information of one item)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec     250\n",
       "ecc    250\n",
       "er     250\n",
       "erc    250\n",
       "gc     250\n",
       "gcc    250\n",
       "hpc    250\n",
       "Name: idx.id2, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['idx.id2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was actually chosen.\n",
    "item_index = df[df['depvar'] == True].sort_values(by='idx.id1')['idx.id2'].reset_index(drop=True)\n",
    "item_names = ['ec', 'ecc', 'er', 'erc', 'gc', 'gcc', 'hpc']\n",
    "num_items = df['idx.id2'].nunique()\n",
    "# cardinal encoder.\n",
    "encoder = dict(zip(item_names, range(num_items)))\n",
    "item_index = item_index.map(lambda x: encoder[x])\n",
    "item_index = torch.LongTensor(item_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be training our model with `PyTorch`, we need to encode item names to integers (from 0 to 6).\n",
    "We do this manually in this exercise given the small amount of items, for more items, one can use [sklearn.preprocessing.OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) to encode.\n",
    "\n",
    "Raw item names will be encoded as the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ec': 0, 'ecc': 1, 'er': 2, 'erc': 3, 'gc': 4, 'gcc': 5, 'hpc': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nest Level Dataset\n",
    "We firstly construct the nest-level dataset, however, there is no observable that is constant within the same nest, so we don't need to include any observable tensor to the `nest_dataset`.\n",
    "\n",
    "All we need to do is adding the `item_index` (i.e., which item is chosen) to the dataset, so that `nest_dataset` knows the total number of choices made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "# nest feature: no nest feature, all features are item-level.\n",
    "nest_dataset = ChoiceDataset(item_index=item_index.clone()).to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Level Dataset\n",
    "For simplicity, we treat each purchasing record as its own session. Moreover, we treat all observables as price observables (i.e., varying by both session and item).\n",
    "\n",
    "Since there are 7 observables in total, the resulted `price_obs` has shape (250, 7, 7) corresponding to `number_of_sessions` by `number_of_items` by `number_of_observables`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item feature.\n",
    "item_feat_cols = ['ich', 'och', 'icca', 'occa', 'inc.room', 'inc.cooling', 'int.cooling']\n",
    "price_obs = utils.pivot3d(df, dim0='idx.id1', dim1='idx.id2', values=item_feat_cols)\n",
    "price_obs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we construct the item level dataset by providing both `item_index` and `price_obs`.\n",
    "\n",
    "We move `item_dataset` to the appropriate device as well. This is only necessary if we are using GPU to accelerate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "item_dataset = ChoiceDataset(item_index=item_index, price_obs=price_obs).to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we chain the nest-level and item-level dataset into a single `JointDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JointDataset(nest=nest_dataset, item=item_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can print the joint dataset to see its contents, and tensors contained in each of these sub-datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointDataset with 2 sub-datasets: (\n",
      "\tnest: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cpu)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cpu)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "There are multiple ways to group 7 items into nests, different classification will result in different utility functions and estimations (see the background of nested logit models).\n",
    "\n",
    "We will demonstrate the usage of our package by presenting three different categorization schemes and corresponding model estimations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "In the first example, the model is specified to have the *cooling alternatives* `{gcc, ecc, erc, hpc}` in one nest and the *non-cooling alternatives* `{gc, ec, er}` in another nest.\n",
    "\n",
    "We create a `nest_to_item` dictionary to inform the model our categorization scheme. The dictionary should have keys ranging from `0` to `number_of_nests - 1`, each integer corresponds to a nest. The value of each key is a list of item IDs in the nest, the encoding of item names should be exactly the same as in the construction of `item_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_to_item = {0: ['gcc', 'ecc', 'erc', 'hpc'],\n",
    "                1: ['gc', 'ec', 'er']}\n",
    "\n",
    "# encode items to integers.\n",
    "for k, v in nest_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    nest_to_item[k] = sorted(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have item `[1, 3, 5, 6]` in the first nest (i.e., the nest with ID `0`) and the rest of items in the second nest (i.e., the nest with ID `1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 3, 5, 6], 1: [0, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "print(nest_to_item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the `NestedLogitModel` class!\n",
    "\n",
    "The first thing to put in is the `nest_to_item` dictionary we just built.\n",
    "\n",
    "For `nest_coef_variation_dict`, `nest_num_param_dict`, since we don't have any nest-specific observables, we can simply put an empty dictionary there.\n",
    "\n",
    "Coefficients for all observables are constant across items, and there are 7 observables in total.\n",
    "\n",
    "As for `shared_lambda=True`, please refer to the background recap for nested logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_coef_variation_dict={},\n",
    "                         nest_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_formula='',\n",
    "                         item_formula='(price_obs|constant)',\n",
    "                         dataset=dataset,\n",
    "                         shared_lambda=True)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the model to get summary information of the `NestedLogitModel` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: We are computing the standard errors using $\\sqrt{\\text{diag}(H^{-1})}$, where $H$ is the\n",
    "hessian of negative log-likelihood with respect to model parameters. This leads to slight different\n",
    "results compared with R implementation.\n",
    "\n",
    "\n",
    "Here we use the LBFGS optimizer since we are working on a small dataset and 8 coefficients to be estimated. For larger datasets and larger models, we recommend using the Adam optimizer instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "==================== data set received ====================\n",
      "[Train dataset] JointDataset with 2 sub-datasets: (\n",
      "\tnest: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cpu)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cpu)\n",
      ")\n",
      "[Validation dataset] None\n",
      "[Test dataset] None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | NestedLogitModel | 8     \n",
      "-------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 136.14it/s, loss=178, v_num=29]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 121.79it/s, loss=178, v_num=29]\n",
      "Time taken for training: 13.282686233520508\n",
      "Skip testing, no test dataset is provided.\n",
      "==================== model results ====================\n",
      "Log-likelihood: [Training] -178.124755859375, [Validation] N/A, [Test] N/A\n",
      "\n",
      "| Coefficient                |   Estimation |   Std. Err. |   z-value |    Pr(>|z|) | Significance   |\n",
      "|:---------------------------|-------------:|------------:|----------:|------------:|:---------------|\n",
      "| lambda_weight_0            |     0.585898 |   0.166624  |   3.51628 | 0.000437634 | ***            |\n",
      "| item_price_obs[constant]_0 |    -0.554846 |   0.144515  |  -3.83936 | 0.000123357 | ***            |\n",
      "| item_price_obs[constant]_1 |    -0.857842 |   0.237496  |  -3.61203 | 0.000303804 | ***            |\n",
      "| item_price_obs[constant]_2 |    -0.225084 |   0.110576  |  -2.03556 | 0.0417943   | *              |\n",
      "| item_price_obs[constant]_3 |    -1.08945  |   1.03675   |  -1.05084 | 0.293332    |                |\n",
      "| item_price_obs[constant]_4 |    -0.37895  |   0.100705  |  -3.76299 | 0.000167895 | ***            |\n",
      "| item_price_obs[constant]_5 |     0.249572 |   0.0518543 |   4.81295 | 1.4872e-06  | ***            |\n",
      "| item_price_obs[constant]_6 |    -5.99973  |   4.82952   |  -1.2423  | 0.214124    |                |\n",
      "Significance codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (nest_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset, num_epochs=1000, model_optimizer=\"LBFGS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R Output\n",
    "Here we provide the output from `mlogit` model in `R` for estimation reference.\n",
    "\n",
    "Coefficient names reported are slightly different in `Python` and `R`, please use the following table for comparison. Please note that the `lambda_weight_0` in `Python` (at the top) corresponds to the `iv` (inclusive value) in `R` (at the bottom). Orderings of coefficients for observables should be the same in both languages.\n",
    "\n",
    "| Coefficient (Python) |   Coefficient (R) |\n",
    "|:-----------------|:-------------:|\n",
    "| lambda_weight_0  |     iv |\n",
    "| item_price_obs_0 |    ich |\n",
    "| item_price_obs_1 |    och  |\n",
    "| item_price_obs_2 |    icca |\n",
    "| item_price_obs_3 |    occa  |\n",
    "| item_price_obs_4 |    inc.room |\n",
    "| item_price_obs_5 |    inc.cooling  |\n",
    "| item_price_obs_6 |    int.cooling  |\n",
    "\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(cooling = c(\"gcc\", \n",
    "##     \"ecc\", \"erc\", \"hpc\"), other = c(\"gc\", \"ec\", \"er\")), un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 11 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 7.26E-06 \n",
    "## successive function values within tolerance limits \n",
    "## \n",
    "## Coefficients :\n",
    "##              Estimate Std. Error z-value  Pr(>|z|)    \n",
    "## ich         -0.554878   0.144205 -3.8478 0.0001192 ***\n",
    "## och         -0.857886   0.255313 -3.3601 0.0007791 ***\n",
    "## icca        -0.225079   0.144423 -1.5585 0.1191212    \n",
    "## occa        -1.089458   1.219821 -0.8931 0.3717882    \n",
    "## inc.room    -0.378971   0.099631 -3.8038 0.0001425 ***\n",
    "## inc.cooling  0.249575   0.059213  4.2149 2.499e-05 ***\n",
    "## int.cooling -6.000415   5.562423 -1.0787 0.2807030    \n",
    "## iv           0.585922   0.179708  3.2604 0.0011125 ** \n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -178.12\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "The second example is similar to the first one, but we change the way we group items into different nests.\n",
    "Re-estimate the model with the room alternatives in one nest and the central alternatives in another nest. (Note that a heat pump is a central system.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nest_to_item = {0: ['ec', 'ecc', 'gc', 'gcc', 'hpc'],\n",
    "                    1: ['er', 'erc']}\n",
    "for k, v in nest_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    nest_to_item[k] = sorted(v)\n",
    "\n",
    "# these two initializations are equivalent.\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_coef_variation_dict={},\n",
    "                         nest_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "print(model)\n",
    "\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_formula='',\n",
    "                         item_formula='(price_obs|constant)',\n",
    "                         dataset=dataset,\n",
    "                         shared_lambda=True)\n",
    "print(model)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "==================== data set received ====================\n",
      "[Train dataset] JointDataset with 2 sub-datasets: (\n",
      "\tnest: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cpu)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cpu)\n",
      ")\n",
      "[Validation dataset] None\n",
      "[Test dataset] None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | NestedLogitModel | 8     \n",
      "-------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 116.29it/s, loss=180, v_num=30]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 107.92it/s, loss=180, v_num=30]\n",
      "Time taken for training: 7.460475206375122\n",
      "Skip testing, no test dataset is provided.\n",
      "==================== model results ====================\n",
      "Log-likelihood: [Training] -180.02308654785156, [Validation] N/A, [Test] N/A\n",
      "\n",
      "| Coefficient                |   Estimation |   Std. Err. |   z-value |   Pr(>|z|) | Significance   |\n",
      "|:---------------------------|-------------:|------------:|----------:|-----------:|:---------------|\n",
      "| lambda_weight_0            |     1.3621   |    0.55502  |   2.45415 | 0.0141217  | *              |\n",
      "| item_price_obs[constant]_0 |    -1.13826  |    0.444239 |  -2.56226 | 0.0103993  | *              |\n",
      "| item_price_obs[constant]_1 |    -1.82546  |    0.738092 |  -2.47321 | 0.0133906  | *              |\n",
      "| item_price_obs[constant]_2 |    -0.337469 |    0.20258  |  -1.66585 | 0.0957429  |                |\n",
      "| item_price_obs[constant]_3 |    -2.06347  |    1.76159  |  -1.17136 | 0.241453   |                |\n",
      "| item_price_obs[constant]_4 |    -0.757264 |    0.278476 |  -2.71931 | 0.00654181 | **             |\n",
      "| item_price_obs[constant]_5 |     0.416903 |    0.170012 |   2.4522  | 0.0141987  | *              |\n",
      "| item_price_obs[constant]_6 |   -13.8256   |    8.09395  |  -1.70814 | 0.0876098  |                |\n",
      "Significance codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (nest_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset, num_epochs=1000, model_optimizer=\"LBFGS\", learning_rate=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R Output\n",
    "\n",
    "You can use the table for converting coefficient names reported by `Python` and `R`:\n",
    "\n",
    "| Coefficient (Python) |   Coefficient (R) |\n",
    "|:-----------------|:-------------:|\n",
    "| lambda_weight_0  |     iv |\n",
    "| item_price_obs_0 |    ich |\n",
    "| item_price_obs_1 |    och  |\n",
    "| item_price_obs_2 |    icca |\n",
    "| item_price_obs_3 |    occa  |\n",
    "| item_price_obs_4 |    inc.room |\n",
    "| item_price_obs_5 |    inc.cooling  |\n",
    "| item_price_obs_6 |    int.cooling  |\n",
    "\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(central = c(\"ec\", \n",
    "##     \"ecc\", \"gc\", \"gcc\", \"hpc\"), room = c(\"er\", \"erc\")), un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 10 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 5.87E-07 \n",
    "## gradient close to zero \n",
    "## \n",
    "## Coefficients :\n",
    "##              Estimate Std. Error z-value Pr(>|z|)  \n",
    "## ich          -1.13818    0.54216 -2.0993  0.03579 *\n",
    "## och          -1.82532    0.93228 -1.9579  0.05024 .\n",
    "## icca         -0.33746    0.26934 -1.2529  0.21024  \n",
    "## occa         -2.06328    1.89726 -1.0875  0.27681  \n",
    "## inc.room     -0.75722    0.34292 -2.2081  0.02723 *\n",
    "## inc.cooling   0.41689    0.20742  2.0099  0.04444 *\n",
    "## int.cooling -13.82487    7.94031 -1.7411  0.08167 .\n",
    "## iv            1.36201    0.65393  2.0828  0.03727 *\n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -180.02\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "For the third example, we now group items into three nests. Specifically, we have items `gcc`, `ecc` and `erc` in the first nest (nest `0` in the `nest_to_item` dictionary), `hpc` in a nest (nest `1`) alone, and items `gc`, `ec` and `er` in the last nest (nest `2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_to_item = {0: ['gcc', 'ecc', 'erc'],\n",
    "                1: ['hpc'],\n",
    "                2: ['gc', 'ec', 'er']}\n",
    "for k, v in nest_to_item.items():\n",
    "    v = [encoder[item] for item in v]\n",
    "    nest_to_item[k] = sorted(v)\n",
    "\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_coef_variation_dict={},\n",
    "                         nest_num_param_dict={},\n",
    "                         item_coef_variation_dict={'price_obs': 'constant'},\n",
    "                         item_num_param_dict={'price_obs': 7},\n",
    "                         shared_lambda=True)\n",
    "\n",
    "model = NestedLogitModel(nest_to_item=nest_to_item,\n",
    "                         nest_formula='',\n",
    "                         item_formula='(price_obs|constant)',\n",
    "                         dataset=dataset,\n",
    "                         shared_lambda=True)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== model received ====================\n",
      "NestedLogitModel(\n",
      "  (nest_coef_dict): ModuleDict()\n",
      "  (item_coef_dict): ModuleDict(\n",
      "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "==================== data set received ====================\n",
      "[Train dataset] JointDataset with 2 sub-datasets: (\n",
      "\tnest: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], device=cpu)\n",
      "\titem: ChoiceDataset(label=[], item_index=[250], user_index=[], session_index=[250], item_availability=[], price_obs=[250, 7, 7], device=cpu)\n",
      ")\n",
      "[Validation dataset] None\n",
      "[Test dataset] None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | NestedLogitModel | 8     \n",
      "-------------------------------------------\n",
      "8         Trainable params\n",
      "0         Non-trainable params\n",
      "8         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 142.92it/s, loss=180, v_num=31]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 126.62it/s, loss=180, v_num=31]\n",
      "Time taken for training: 7.50447416305542\n",
      "Skip testing, no test dataset is provided.\n",
      "==================== model results ====================\n",
      "Log-likelihood: [Training] -180.26324462890625, [Validation] N/A, [Test] N/A\n",
      "\n",
      "| Coefficient                |   Estimation |   Std. Err. |   z-value |    Pr(>|z|) | Significance   |\n",
      "|:---------------------------|-------------:|------------:|----------:|------------:|:---------------|\n",
      "| lambda_weight_0            |     0.956541 |   0.197062  |   4.854   | 1.20994e-06 | ***            |\n",
      "| item_price_obs[constant]_0 |    -0.838394 |   0.099096  |  -8.46042 | 0           | ***            |\n",
      "| item_price_obs[constant]_1 |    -1.3316   |   0.184895  |  -7.2019  | 5.93747e-13 | ***            |\n",
      "| item_price_obs[constant]_2 |    -0.25613  |   0.1263    |  -2.02795 | 0.0425655   | *              |\n",
      "| item_price_obs[constant]_3 |    -1.40566  |   1.14467   |  -1.22801 | 0.219443    |                |\n",
      "| item_price_obs[constant]_4 |    -0.571352 |   0.0750316 |  -7.61482 | 2.64233e-14 | ***            |\n",
      "| item_price_obs[constant]_5 |     0.311357 |   0.0550892 |   5.65187 | 1.58715e-08 | ***            |\n",
      "| item_price_obs[constant]_6 |   -10.4134   |   5.19301   |  -2.00528 | 0.0449335   | *              |\n",
      "Significance codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedLogitModel(\n",
       "  (nest_coef_dict): ModuleDict()\n",
       "  (item_coef_dict): ModuleDict(\n",
       "    (price_obs[constant]): Coefficient(variation=constant, num_items=7, num_users=None, num_params=7, 7 trainable parameters in total, device=cpu).\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, dataset, num_epochs=1000, model_optimizer=\"LBFGS\", learning_rate=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R Output\n",
    "\n",
    "You can use the table for converting coefficient names reported by `Python` and `R`:\n",
    "\n",
    "| Coefficient (Python) |   Coefficient (R) |\n",
    "|:-----------------|:-------------:|\n",
    "| lambda_weight_0  |     iv |\n",
    "| item_price_obs_0 |    ich |\n",
    "| item_price_obs_1 |    och  |\n",
    "| item_price_obs_2 |    icca |\n",
    "| item_price_obs_3 |    occa  |\n",
    "| item_price_obs_4 |    inc.room |\n",
    "| item_price_obs_5 |    inc.cooling  |\n",
    "| item_price_obs_6 |    int.cooling  |\n",
    "\n",
    "```\n",
    "## \n",
    "## Call:\n",
    "## mlogit(formula = depvar ~ ich + och + icca + occa + inc.room + \n",
    "##     inc.cooling + int.cooling | 0, data = HC, nests = list(n1 = c(\"gcc\", \n",
    "##     \"ecc\", \"erc\"), n2 = c(\"hpc\"), n3 = c(\"gc\", \"ec\", \"er\")), \n",
    "##     un.nest.el = TRUE)\n",
    "## \n",
    "## Frequencies of alternatives:choice\n",
    "##    ec   ecc    er   erc    gc   gcc   hpc \n",
    "## 0.004 0.016 0.032 0.004 0.096 0.744 0.104 \n",
    "## \n",
    "## bfgs method\n",
    "## 8 iterations, 0h:0m:0s \n",
    "## g'(-H)^-1g = 3.71E-08 \n",
    "## gradient close to zero \n",
    "## \n",
    "## Coefficients :\n",
    "##               Estimate Std. Error z-value  Pr(>|z|)    \n",
    "## ich          -0.838394   0.100546 -8.3384 < 2.2e-16 ***\n",
    "## och          -1.331598   0.252069 -5.2827 1.273e-07 ***\n",
    "## icca         -0.256131   0.145564 -1.7596   0.07848 .  \n",
    "## occa         -1.405656   1.207281 -1.1643   0.24430    \n",
    "## inc.room     -0.571352   0.077950 -7.3297 2.307e-13 ***\n",
    "## inc.cooling   0.311355   0.056357  5.5247 3.301e-08 ***\n",
    "## int.cooling -10.413384   5.612445 -1.8554   0.06354 .  \n",
    "## iv            0.956544   0.180722  5.2929 1.204e-07 ***\n",
    "## ---\n",
    "## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
    "## \n",
    "## Log-Likelihood: -180.26\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
