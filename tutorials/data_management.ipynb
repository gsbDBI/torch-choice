{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management Tutorial\n",
    "**Author: Tianyu Du (tianyudu@stanford.edu)**\n",
    "\n",
    "This notebook aims to help users understand the functionality of `ChoiceDataset` object. The `ChoiceDataset` is the core\n",
    "class to hold \n",
    "\n",
    "Since this package was initially proposed for modelling consumer choices, the naming convention follows the consumer choice\n",
    "scenario.\n",
    "\n",
    "Now imagine that you have access to purchase records of customers of a supermarket.\n",
    "\n",
    "## Core Components of the Dataset\n",
    "We begin with notations and essential factors of the prediction problem. Suppose there are $I$ items under our consideration and the set of **items** $i \\in \\{1,2,\\dots,I\\}$ can be grouped into $C$ **categories** $c \\in \\{1,2,\\dots,C\\}$, further, let $I_c$ denote the collection of items in category $c$ (**NOTE** category information is only needed if you are running the *nested* logit model).\n",
    "\n",
    "Since we will be using PyTorch to train our model, we represent their identities using integers. Moreover, this document will use lower cases $i, c$, etc to index items and categories respectively.\n",
    "\n",
    "Let $B$ denote the number of purchasing records in the dataset, each $b \\in \\{1,2,\\dots, B\\}$ record is associated with an **user** $u \\in \\{1,2,\\dots,U\\}$ and a **session** $s \\in \\{1,2,\\dots, S\\}$. When there are multiple items bought in the same shopping trip, there will be multiple rows in the dataset with the same $(u, s)$.\n",
    "\n",
    "One canonical example of session $s$ is the date of purchase or the shopping trip. \n",
    "\n",
    "The `ChoiceDataset` data manager is initialized with the following PyTorch tensors:\n",
    "\n",
    "1. `label` $\\in \\{1,2,\\dots,I\\}^B$ : the ID of the bought item.\n",
    "2. `user_index` $\\in \\{1,2,\\dots,U\\}^B$: the ID of the corresponding user (shopper).\n",
    "3. `session_index` $\\in \\{1,2,\\dots,S\\}^B$\n",
    "4. `item_availability` $\\in \\{\\texttt{True}, \\texttt{False}\\}^{S\\times I}$  identifies the availability of items in each session, the model will ignore unavailable items while making prediction.\n",
    "5. `user_obs` $\\in \\mathbb{R}^{U\\times K_{user}}$\n",
    "6. `item_obs` $\\in \\mathbb{R}^{I\\times K_{item}}$\n",
    "7. `session_obs` $\\in \\mathbb{R}^{S \\times K_{session}}$\n",
    "8. `price_obs` $\\in \\mathbb{R}^{S \\times I \\times K_{price}}$\n",
    "\n",
    "## Example\n",
    "Suppose we have a dataset of pucrhase history from two stores (Store A and B) on two dates (Sep 16 and 17), both stores sell {apple, banana, orange} (`num_items=3`) and there are three people came to those stores between Sep 16 and 17.\n",
    "\n",
    "| user_index | session_index       | label  |\n",
    "| ---------- | ------------------- | ------ |\n",
    "| Amy        | Sep-17-2021-Store-A | banana |\n",
    "| Ben        | Sep-17-2021-Store-B | apple  |\n",
    "| Ben        | Sep-16-2021-Store-A | orange |\n",
    "| Charlie    | Sep-16-2021-Store-B | apple  |\n",
    "| Charlie    | Sep-16-2021-Store-B | orange |\n",
    "\n",
    "**NOTE**: For demonstration purpose, the example dataset has `user_index`, `session_index` and `label` as strings, they should be consecutive integers in actual production. One can easily convert them to integers using `sklearn.preprocessing.LabelEncoder`. In this case, `user_index=[0,1,1,2,2]`, `session_index=[0,1,2,3,3]`, and `label=[0,1,2,1,2]`. Suppose we believe people's purchasing decision depends on nutrition levels of these fruits, suppose apple has the highest nutrition level and banana has the lowest one, we can add `item_obs=[1.5, 12.0, 3.3]` (recall the integer encoding of fruits based on the `label` variable above. These numbers were arbitrary )\n",
    "\n",
    "**NOTE**: If someone went to one store and bought multiple items (e.g., Charlie bought both apple and orange at Store B on Sep-16), we include them as separate rows in the dataset and model them independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_choice.data import ChoiceDataset, JointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_shape(d):\n",
    "    for key, val in d.items():\n",
    "        if torch.is_tensor(val):\n",
    "            print(f'dict.{key}.shape={val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating  `ChoiceDataset` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates some fake input features, feel free to modify it as you want.\n",
    "num_users = 10\n",
    "num_items = 4\n",
    "num_sessions = 500\n",
    "\n",
    "length_of_dataset = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Gather Information.\n",
    "The first step is to create tensors encompassing information about users, items and sessions. Here we are providing some random tensors for demonstration purpose only. Please check out tutorials for the logit model and the nested logit model for real examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create observables/features, the number of parameters are\n",
    "# arbitrarily chosen.\n",
    "user_obs = torch.randn(num_users, 128)  # generate 128 features for each user, e.g., race, gender.\n",
    "item_obs = torch.randn(num_items, 64)  # generate 64 features for each user, e.g., quality.\n",
    "session_obs = torch.randn(num_sessions, 10)  # generate 10 features for each session, e.g., weekday indicator. \n",
    "price_obs = torch.randn(num_sessions, num_items, 12)  # generate 12 features for each session user pair, e.g., the budget of that user at the shopping day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.LongTensor(np.random.choice(num_items, size=length_of_dataset))\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=length_of_dataset))\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=length_of_dataset))\n",
    "\n",
    "# assume all items are available in all sessions.\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the `ChoiceDataset`.\n",
    "You can construct a choice set using the following code, which manage all information for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    label=label,  # required.\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    price_obs=price_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__repr__` string of choice dataset object provides you with shapes of tensors the dataset is holding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `num_{users, items, sessions}` attribute to obtain the number of users, items, and sessions, they are determined automatically from the `{user, item, session}_obs` tensors provided while initializing the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.num_users=10\n",
      "dataset.num_items=4\n",
      "dataset.num_sessions=500\n",
      "len(dataset)=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'{dataset.num_users=:}')\n",
    "print(f'{dataset.num_items=:}')\n",
    "print(f'{dataset.num_sessions=:}')\n",
    "print(f'{len(dataset)=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 2, 1, 3, 0, 0, 0, 3, 2])\n",
      "tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.])\n",
      "tensor([2, 1, 2, 1, 3, 0, 0, 0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# clone\n",
    "print(dataset.label[:10])\n",
    "dataset_cloned = dataset.clone()\n",
    "dataset_cloned.label = 99 * torch.ones(num_sessions)\n",
    "print(dataset_cloned.label[:10])\n",
    "print(dataset.label[:10])  # does not change the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.device=cpu\n",
      "dataset.label.device=cpu\n",
      "dataset.user_index.device=cpu\n",
      "dataset.session_index.device=cpu\n",
      "dataset.device=cuda:0\n",
      "dataset.label.device=cuda:0\n",
      "dataset.user_index.device=cuda:0\n",
      "dataset.session_index.device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# move to device\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.label.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')\n",
    "\n",
    "dataset = dataset.to('cuda')\n",
    "\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.label.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: this cell will result errors, this is intentional.\n",
    "# dataset.label = dataset.label.to('cpu')\n",
    "# dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.price_obs.shape=torch.Size([10000, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "# create dictionary inputs for model.forward()\n",
    "# collapse to a dictionary object.\n",
    "print_dict_shape(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7117, 4566, 6732, 7475, 3698])\n",
      "ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
      "ChoiceDataset(label=[5], user_index=[5], session_index=[5], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
      "dict.user_obs.shape=torch.Size([5, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([5, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([5, 4, 10])\n",
      "dict.price_obs.shape=torch.Size([5, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "# __getitem__ to get batch.\n",
    "# pick 5 random sessions as the mini-batch.\n",
    "dataset = dataset.to('cpu')\n",
    "indices = torch.Tensor(np.random.choice(len(dataset), size=5, replace=False)).long()\n",
    "print(indices)\n",
    "subset = dataset[indices]\n",
    "print(dataset)\n",
    "print(subset)\n",
    "print_dict_shape(subset.x_dict)\n",
    "\n",
    "assert torch.all(dataset.x_dict['price_obs'][indices, :, :] == subset.x_dict['price_obs'])\n",
    "assert torch.all(dataset.label[indices] == subset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 1, 0, 2])\n",
      "tensor([3, 1, 1, 0, 2])\n",
      "tensor([4, 2, 2, 1, 3])\n",
      "tensor([3, 1, 1, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "print(subset.label)\n",
    "print(dataset.label[indices])\n",
    "\n",
    "subset.label += 1  # modifying the batch does not change the original dataset.\n",
    "\n",
    "print(subset.label)\n",
    "print(dataset.label[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4046)\n",
      "tensor(-0.4046)\n",
      "tensor(0.5954)\n",
      "tensor(-0.4046)\n"
     ]
    }
   ],
   "source": [
    "print(subset.item_obs[0, 0])\n",
    "print(dataset.item_obs[0, 0])\n",
    "subset.item_obs += 1\n",
    "print(subset.item_obs[0, 0])\n",
    "print(dataset.item_obs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139651371619408\n",
      "139651371561184\n"
     ]
    }
   ],
   "source": [
    "print(id(subset.label))\n",
    "print(id(dataset.label[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch dataloader for the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data.sampler import BatchSampler, SequentialSampler, RandomSampler\n",
    "# shuffle = False\n",
    "# batch_size = 32\n",
    "\n",
    "# sampler = BatchSampler(\n",
    "#     RandomSampler(dataset) if shuffle else SequentialSampler(dataset),\n",
    "#     batch_size=batch_size,\n",
    "#     drop_last=False)\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(dataset,\n",
    "#                                          sampler=sampler,\n",
    "#                                          num_workers=0,  # 0 if dataset.device == 'cuda' else os.cpu_count(),\n",
    "#                                          collate_fn=lambda x: x[0],\n",
    "#                                          pin_memory=(dataset.device == 'cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_obs.shape=torch.Size([4, 64])\n",
      "item_obs_all.shape=torch.Size([500, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "# print(f'{item_obs.shape=:}')\n",
    "# item_obs_all = item_obs.view(1, num_items, -1).expand(num_sessions, -1, -1)\n",
    "# item_obs_all = item_obs_all.to(dataset.device)\n",
    "# label_all = label.to(dataset.device)\n",
    "# print(f'{item_obs_all.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(dataloader):\n",
    "#     # check consistency.\n",
    "#     first, last = i * batch_size, min(len(dataset), (i + 1) * batch_size)\n",
    "#     idx = torch.arange(first, last)\n",
    "#     assert torch.all(item_obs_all[idx, :, :] == batch.x_dict['item_obs'])\n",
    "#     assert torch.all(label_all[idx] == batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Multiple Datasets: `JointDataset` Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset.clone()\n",
    "dataset2 = dataset.clone()\n",
    "joint_dataset = JointDataset(the_dataset=dataset1, another_dataset=dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JointDataset with 2 sub-datasets: (\n",
       "\tthe_dataset: ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
       "\tanother_dataset: ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7dc80b2c4d9dbaf52e273e24444ebf2c26f0fdc466c7e783c99ad3a1ce41bbd"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
