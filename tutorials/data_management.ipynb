{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Data Management\n",
    "**Author: Tianyu Du (tianyudu@stanford.edu)**\n",
    "\n",
    "**Note**: please go through the introduction tutorial [here](https://gsbdbi.github.io/torch-choice/intro/) before proceeding.\n",
    "\n",
    "This notebook aims to help users understand the functionality of `ChoiceDataset` object.\n",
    "The `ChoiceDataset` is an instance of the more general PyTorch dataset object holding information of consumer choices. The `ChoiceDataset` offers easy, clean and efficient data management. The Jupyter-notebook version of this tutorial can be found [here](https://github.com/gsbDBI/torch-choice/blob/main/tutorials/data_management.ipynb).\n",
    "\n",
    "This tutorial provides in-depth explanations on how the `torch-choice` library manages data. We are also providing an easy-to-use data wrapper converting long-format dataset to `ChoiceDataset` [here](https://gsbdbi.github.io/torch-choice/easy_data_management/), you can harness the `torch-choice` library without going through this tutorial. \n",
    "\n",
    "**Note**: since this package was initially proposed for modelling consumer choices, attribute names of `ChoiceDataset` are borrowed from the consumer choice literature.\n",
    "\n",
    "**Note**: PyTorch uses the term **tensor** to denote high dimensional matrices, we will be using **tensor** and **matrix** interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After walking through this tutorial, you should be abel to initiate a `ChoiceDataset` object as the following and use it to manage data.\n",
    "```python\n",
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    item_index=item_index,  # required.\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    price_obs=price_obs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observables\n",
    "Observables are tensors with specific shapes, we classify observables into four categories based on their variations.\n",
    "\n",
    "#### Basic Usage\n",
    "Optionally, the researcher can incorporate observables of, for example, users and items. Currently, the package support the following types of observables, where $K_{...}$ denote the number of observables.\n",
    "\n",
    "1. `user_obs` $\\in \\mathbb{R}^{U\\times K_{user}}$: user observables such as user age.\n",
    "2. `item_obs` $\\in \\mathbb{R}^{I\\times K_{item}}$: item observables such as item quality.\n",
    "3. `session_obs` $\\in \\mathbb{R}^{S \\times K_{session}}$: session observable such as whether the purchase was made on weekdays.\n",
    "4. `price_obs` $\\in \\mathbb{R}^{S \\times I \\times K_{price}}$, price observables are values depending on **both** session and item such as the price of item.\n",
    "\n",
    "The researcher should supply them with as appropriate keyword arguments while constructing the `ChoiceDataset` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Advanced Usage: Additional Observables\n",
    "In some cases, the researcher have multiple sets of user (or item, or session, or price) observables, say *user income* (a scalar variable) and *user market membership*. The *user income* a matrix in $\\mathbb{R}^{U\\times 1}$. Further, suppose there are four types of market membership: no-membership, silver-membership, gold-membership, and diamond-membership. The *user market membership* is a binary matrix in $\\{0, 1\\}^{U\\times 4}$ if we one-hot encode users' membership status.\n",
    "\n",
    "In this case, the researcher can either\n",
    "1. concatenate `user_income` and `user_market_membership` to a $\\mathbb{R}^{U\\times (1+4)}$ matrix and supply it as a single `user_obs` as the following:\n",
    "```python\n",
    "dataset = ChoiceDataset(..., user_obs=torch.cat([user_income, user_market_membership], dim=1), ...)\n",
    "```\n",
    "2. Or, supply these two sets of observables separately, namely a `user_income` $\\in \\mathbb{R}^{U \\times 1}$ matrix and a `user_market_membership` $\\in \\mathbb{R}^{U \\times 4}$ matrix as the following:\n",
    "```python\n",
    "dataset = ChoiceDataset(..., user_income=user_income, user_market_membership=user_market_membership, ...)\n",
    "```\n",
    "\n",
    "Supplying two separate sets of observables is particularly useful when the researcher wants different kinds of coefficients for different kinds of observables.\n",
    "\n",
    "For example, the researcher wishes to model the utility for user $u$ to purchase item $i$ in session $s$ as the following:\n",
    "\n",
    "$$\n",
    "U_{usi} = \\beta_{i} X^{(u)}_{user\\ income} + \\gamma X^{(u)}_{user\\ market\\ membership} + \\varepsilon\n",
    "$$\n",
    "\n",
    "Please note that the $\\beta_i$ coefficient has an $i$ subscript, which means it's item specific. The $\\gamma$ coefficient has no subscript, which means it's the same for all items.\n",
    "\n",
    "The coefficient for user income is item-specific so that it captures the nature of the product (i.e., a luxury or an essential good). Additionally, the utility representation admits an user market membership becomes shoppers with active memberships tend to purchase more, and the coefficient of this term is constant across all items.\n",
    "\n",
    "As we will cover later in the modelling section, we need to supply two user observable tensors in this case for the model to build coefficient with different levels of variations (i.e., item-specific coefficients versus constant coefficients). In this case, the researcher needs to supply two tensors `user_income` and `user_market_membership` as keyword arguments to the `ChoiceDataset` constructor.\n",
    "\n",
    "Generally, the `ChoiceDataset` handles multiple user/item/session/price observables internally, the `ChoiceDataset` class identifies the variation of observables by their prefixes. For example, every keyword arguments passed into `ChoiceDataset` with name starting with `item_` (except for the reserved `item_availability`) will be treated as item observable tensors.\n",
    "Similarly, all keywords with names starting `user_`, `session_` and `price_` (except for reserved names like `user_index` and `session_index` mentioned above) will be interpreted as user/session/price observable tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_choice.data import ChoiceDataset, JointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get a helper\n",
    "def print_dict_shape(d):\n",
    "    for key, val in d.items():\n",
    "        if torch.is_tensor(val):\n",
    "            print(f'dict.{key}.shape={val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating  `ChoiceDataset` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to modify it as you want.\n",
    "num_users = 10\n",
    "num_items = 4\n",
    "num_sessions = 500\n",
    "\n",
    "length_of_dataset = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate some random purchase records and observables\n",
    "We will be creating a randomly generated dataset with 10000 purchase records from 10 users, 4 items and 500 sessions.\n",
    "\n",
    "We use the term **purchase record** to denote the observation in the dataset due to the convention in Stata documentation (because *observation* meant something else in the Stata documentation and we don't want to confuse existing Stata users).\n",
    "\n",
    "As mentioned in the introduction tutorial, one purchase record consists of *who* (i.e., user) bought *what* (i.e., item) *when* and *where* (i.e., session). \n",
    "\n",
    "The length of the dataset equals the number of purchase records in it.\n",
    "\n",
    "The first step is to randomly generate the purchase records using the following code. For simplicity, we assume all items are available in all sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create observables/features, the number of parameters are arbitrarily chosen.\n",
    "# generate 128 features for each user, e.g., race, gender.\n",
    "user_obs = torch.randn(num_users, 128)\n",
    "# generate 64 features for each user, e.g., quality.\n",
    "item_obs = torch.randn(num_items, 64)\n",
    "# generate 10 features for each session, e.g., weekday indicator. \n",
    "session_obs = torch.randn(num_sessions, 10)\n",
    "# generate 12 features for each session user pair, e.g., the budget of that user at the shopping day.\n",
    "price_obs = torch.randn(num_sessions, num_items, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate random observable tensors for users, items, sessions and price observables, the size of observables of each type (i.e., the last dimension in the shape) is arbitrarily chosen.\n",
    "\n",
    "**Notes on Encodings** Since we will be using PyTorch to train our model, we represent their identities with *consecutive* integer values instead of the raw human-readable names of items (e.g., Dell 24-inch LCD monitor). Similarly, you would need to encode user indices and session indices as well.\n",
    "Raw item names can be encoded easily with [sklearn.preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) (The [sklearn.preprocessing.OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) works as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_index = torch.LongTensor(np.random.choice(num_items, size=length_of_dataset))\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=length_of_dataset))\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=length_of_dataset))\n",
    "\n",
    "# assume all items are available in all sessions.\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the `ChoiceDataset`.\n",
    "You can construct a choice set using the following code, which manage all information for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    item_index=item_index,  # required.\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    price_obs=price_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you can do with the `ChoiceDataset`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `print(dataset)` and `dataset.__str__`\n",
    "The command `print(dataset)` will provide a quick overview of shapes of tensors included in the object as well as where the dataset is located (i.e., host memory or GPU memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dataset.num_{users, items, sessions}`\n",
    "You can use the `num_{users, items, sessions}` attribute to obtain the number of users, items, and sessions, they are determined automatically from the `{user, item, session}_obs` tensors provided while initializing the dataset object.\n",
    "\n",
    "**Note**: the print `=:` operator requires Python3.8 or higher, you can remove `=:` if you are using an earlier copy of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.num_users=10\n",
      "dataset.num_items=4\n",
      "dataset.num_sessions=500\n",
      "len(dataset)=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'{dataset.num_users=:}')\n",
    "print(f'{dataset.num_items=:}')\n",
    "print(f'{dataset.num_sessions=:}')\n",
    "print(f'{len(dataset)=:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dataset.clone()`\n",
    "The `ChoiceDataset` offers a `clone` method allow you to make copy of the dataset, you can modify the cloned dataset arbitrarily without changing the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1])\n",
      "tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.])\n",
      "tensor([2, 2, 3, 1, 3, 2, 2, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# clone\n",
    "print(dataset.item_index[:10])\n",
    "dataset_cloned = dataset.clone()\n",
    "dataset_cloned.item_index = 99 * torch.ones(num_sessions)\n",
    "print(dataset_cloned.item_index[:10])\n",
    "print(dataset.item_index[:10])  # does not change the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dataset.to('cuda')` and `dataset._check_device_consistency()`.\n",
    "One key advantage of the `torch_choice` and `bemb` is their compatibility with GPUs, you can easily move tensors in a `ChoiceDataset` object between host memory (i.e., cpu memory) and device memory (i.e., GPU memory) using `dataset.to()` method.\n",
    "Please note that the following code runs only if your machine has a compatible GPU and GPU-compatible version of PyTorch installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, one can move data to host-memory using `dataset.to('cpu')`.\n",
    "The dataset also provides a `dataset._check_device_consistency()` method to check if all tensors are on the same device.\n",
    "If we only move the `label` to cpu without moving other tensors, this will result in an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.device=cpu\n",
      "dataset.device=cpu\n",
      "dataset.user_index.device=cpu\n",
      "dataset.session_index.device=cpu\n",
      "dataset.device=cuda:0\n",
      "dataset.item_index.device=cuda:0\n",
      "dataset.user_index.device=cuda:0\n",
      "dataset.session_index.device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# move to device\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')\n",
    "\n",
    "dataset = dataset.to('cuda')\n",
    "\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.item_index.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "(\"Found tensors on different devices: {device(type='cuda', index=0), device(type='cpu')}.\", 'Use dataset.to() method to align devices.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-40d626c6d436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # NOTE: this cell will result errors, this is intentional.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_device_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/torch-choice/torch_choice/data/choice_dataset.py\u001b[0m in \u001b[0;36m_check_device_consistency\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mdevices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             raise Exception(f'Found tensors on different devices: {set(devices)}.',\n\u001b[0m\u001b[1;32m    183\u001b[0m                             'Use dataset.to() method to align devices.')\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (\"Found tensors on different devices: {device(type='cuda', index=0), device(type='cpu')}.\", 'Use dataset.to() method to align devices.')"
     ]
    }
   ],
   "source": [
    "# # NOTE: this cell will result errors, this is intentional.\n",
    "dataset.item_index = dataset.item_index.to('cpu')\n",
    "dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.price_obs.shape=torch.Size([10000, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "# create dictionary inputs for model.forward()\n",
    "# collapse to a dictionary object.\n",
    "print_dict_shape(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset method\n",
    "One can use `dataset[indices]` with `indices` as an integer-valued tensor or array to get the corresponding rows of the dataset.\n",
    "The example code block below queries the 6256-th, 4119-th, 453-th, 5520-th, and 1877-th row of the dataset object.\n",
    "The `item_index`, `user_index`, `session_index` of the resulted subset will be different from the original dataset, but other tensors will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1118,  976, 1956,  290, 8283])\n",
      "ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
      "ChoiceDataset(label=[], item_index=[5], user_index=[5], session_index=[5], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "# __getitem__ to get batch.\n",
    "# pick 5 random sessions as the mini-batch.\n",
    "dataset = dataset.to('cpu')\n",
    "indices = torch.Tensor(np.random.choice(len(dataset), size=5, replace=False)).long()\n",
    "print(indices)\n",
    "subset = dataset[indices]\n",
    "print(dataset)\n",
    "print(subset)\n",
    "# print_dict_shape(subset.x_dict)\n",
    "\n",
    "# assert torch.all(dataset.x_dict['price_obs'][indices, :, :] == subset.x_dict['price_obs'])\n",
    "# assert torch.all(dataset.item_index[indices] == subset.item_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset method internally creates a copy of the datasets so that any modification applied on the subset will **not** be reflected on the original dataset.\n",
    "The researcher can feel free to do in-place modification to the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0])\n",
      "tensor([1, 2, 1, 1, 1])\n",
      "tensor([0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(subset.item_index)\n",
    "print(dataset.item_index[indices])\n",
    "\n",
    "subset.item_index += 1  # modifying the batch does not change the original dataset.\n",
    "\n",
    "print(subset.item_index)\n",
    "print(dataset.item_index[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.5811)\n",
      "tensor(-1.5811)\n",
      "tensor(-0.5811)\n",
      "tensor(-1.5811)\n"
     ]
    }
   ],
   "source": [
    "print(subset.item_obs[0, 0])\n",
    "print(dataset.item_obs[0, 0])\n",
    "subset.item_obs += 1\n",
    "print(subset.item_obs[0, 0])\n",
    "print(dataset.item_obs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140339656298640\n",
      "140339656150528\n"
     ]
    }
   ],
   "source": [
    "print(id(subset.item_index))\n",
    "print(id(dataset.item_index[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch dataloader for the training loop.\n",
    "The `ChoiceDataset` object natively support batch samplers from PyTorch. For demonstration purpose, we turned off the shuffling option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler, SequentialSampler, RandomSampler\n",
    "shuffle = False  # for demonstration purpose.\n",
    "batch_size = 32\n",
    "\n",
    "# Create sampler.\n",
    "sampler = BatchSampler(\n",
    "    RandomSampler(dataset) if shuffle else SequentialSampler(dataset),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         sampler=sampler,\n",
    "                                         num_workers=1,\n",
    "                                         collate_fn=lambda x: x[0],\n",
    "                                         pin_memory=(dataset.device == 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_obs.shape=torch.Size([4, 64])\n",
      "item_obs_all.shape=torch.Size([10000, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'{item_obs.shape=:}')\n",
    "item_obs_all = item_obs.view(1, num_items, -1).expand(len(dataset), -1, -1)\n",
    "item_obs_all = item_obs_all.to(dataset.device)\n",
    "item_index_all = item_index.to(dataset.device)\n",
    "print(f'{item_obs_all.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    first, last = i * batch_size, min(len(dataset), (i + 1) * batch_size)\n",
    "    idx = torch.arange(first, last)\n",
    "    assert torch.all(item_obs_all[idx, :, :] == batch.x_dict['item_obs'])\n",
    "    assert torch.all(item_index_all[idx] == batch.item_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x_dict['item_obs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.price_obs.shape=torch.Size([10000, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "print_dict_shape(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Multiple Datasets: `JointDataset` Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset.clone()\n",
    "dataset2 = dataset.clone()\n",
    "joint_dataset = JointDataset(the_dataset=dataset1, another_dataset=dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JointDataset with 2 sub-datasets: (\n",
       "\tthe_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
       "\tanother_dataset: ChoiceDataset(label=[], item_index=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], price_obs=[500, 4, 12], device=cpu)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_dataset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7dc80b2c4d9dbaf52e273e24444ebf2c26f0fdc466c7e783c99ad3a1ce41bbd"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
