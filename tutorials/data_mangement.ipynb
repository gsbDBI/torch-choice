{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management Tutorial\n",
    "This notebook aims to help users understand the functionality of `ChoiceDataset` object. The `ChoiceDataset` is the core\n",
    "class to hold \n",
    "\n",
    "Since this package was initially proposed for modelling consumer choices, the naming convention follows the consumer choice\n",
    "scenario.\n",
    "\n",
    "Author: Tianyu Du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_choice.data import ChoiceDataset, JointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_shape(d):\n",
    "    for key, val in d.items():\n",
    "        if torch.is_tensor(val):\n",
    "            print(f'dict.{key}.shape={val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating  `ChoiceDataset` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates some fake input features, feel free to modify it as you want.\n",
    "num_users = 10\n",
    "num_items = 4\n",
    "num_sessions = 500\n",
    "\n",
    "length_of_dataset = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create observables/features/covariates, the number of parameters are\n",
    "# arbitrarily chosen.\n",
    "user_obs = torch.randn(num_users, 128)  # generate 128 features for each user, e.g., race, gender.\n",
    "item_obs = torch.randn(num_items, 64)  # generate 64 features for each user, e.g., quality.\n",
    "session_obs = torch.randn(num_sessions, 10)  # generate 10 features for each session, e.g., weekday indicator. \n",
    "taste_obs = torch.randn(num_users, num_items, 20)  # generate 20 features for each user item pair.\n",
    "price_obs = torch.randn(num_sessions, num_items, 12)  # generate 12 features for each session user pair, e.g., the budget of that user at the shopping day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.LongTensor(np.random.choice(num_items, size=length_of_dataset))\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=length_of_dataset))\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=length_of_dataset))\n",
    "\n",
    "# assume all items are available in all sessions.\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    # pre-specified keywords of __init__\n",
    "    label=label,  # required.\n",
    "    # optional:\n",
    "    user_index=user_index,\n",
    "    session_index=session_index,\n",
    "    item_availability=item_availability,\n",
    "    # additional keywords of __init__\n",
    "    user_obs=user_obs,\n",
    "    item_obs=item_obs,\n",
    "    session_obs=session_obs,\n",
    "    taste_obs=taste_obs,\n",
    "    price_obs=price_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], taste_obs=[10, 4, 20], price_obs=[500, 4, 12], device=cpu)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.num_users=10\n",
      "dataset.num_items=4\n",
      "dataset.num_sessions=500\n",
      "len(dataset)=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'{dataset.num_users=:}')\n",
    "print(f'{dataset.num_items=:}')\n",
    "print(f'{dataset.num_sessions=:}')\n",
    "print(f'{len(dataset)=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 3, 2, 1, 2, 2, 0, 0])\n",
      "tensor([99., 99., 99., 99., 99., 99., 99., 99., 99., 99.])\n",
      "tensor([1, 2, 1, 3, 2, 1, 2, 2, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# clone\n",
    "print(dataset.label[:10])\n",
    "dataset_cloned = dataset.clone()\n",
    "dataset_cloned.label = 99 * torch.ones(num_sessions)\n",
    "print(dataset_cloned.label[:10])\n",
    "print(dataset.label[:10])  # does not change the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.device=cpu\n",
      "dataset.label.device=cpu\n",
      "dataset.taste_obs.device=cpu\n",
      "dataset.user_index.device=cpu\n",
      "dataset.session_index.device=cpu\n",
      "dataset.device=cuda:0\n",
      "dataset.label.device=cuda:0\n",
      "dataset.taste_obs.device=cuda:0\n",
      "dataset.user_index.device=cuda:0\n",
      "dataset.session_index.device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# move to device\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.label.device=:}')\n",
    "print(f'{dataset.taste_obs.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')\n",
    "\n",
    "dataset = dataset.to('cuda')\n",
    "\n",
    "print(f'{dataset.device=:}')\n",
    "print(f'{dataset.label.device=:}')\n",
    "print(f'{dataset.taste_obs.device=:}')\n",
    "print(f'{dataset.user_index.device=:}')\n",
    "print(f'{dataset.session_index.device=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: this cell will result errors, this is intentional.\n",
    "# dataset.label = dataset.label.to('cpu')\n",
    "# dataset._check_device_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.user_obs.shape=torch.Size([10000, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([10000, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([10000, 4, 10])\n",
      "dict.taste_obs.shape=torch.Size([10000, 4, 20])\n",
      "dict.price_obs.shape=torch.Size([10000, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "# create dictionary inputs for model.forward()\n",
    "print_dict_shape(dataset.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5608, 3635, 9499, 9746, 6195])\n",
      "ChoiceDataset(label=[10000], user_index=[10000], session_index=[10000], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], taste_obs=[10, 4, 20], price_obs=[500, 4, 12], device=cpu)\n",
      "ChoiceDataset(label=[5], user_index=[5], session_index=[5], item_availability=[500, 4], observable_prefix=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[500, 10], taste_obs=[10, 4, 20], price_obs=[500, 4, 12], device=cpu)\n",
      "dict.user_obs.shape=torch.Size([5, 4, 128])\n",
      "dict.item_obs.shape=torch.Size([5, 4, 64])\n",
      "dict.session_obs.shape=torch.Size([5, 4, 10])\n",
      "dict.taste_obs.shape=torch.Size([5, 4, 20])\n",
      "dict.price_obs.shape=torch.Size([5, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "# __getitem__ to get batch.\n",
    "# pick 5 random sessions as the mini-batch.\n",
    "dataset = dataset.to('cpu')\n",
    "indices = torch.Tensor(np.random.choice(len(dataset), size=5, replace=False)).long()\n",
    "print(indices)\n",
    "subset = dataset[indices]\n",
    "print(dataset)\n",
    "print(subset)\n",
    "print_dict_shape(subset.x_dict)\n",
    "\n",
    "assert torch.all(dataset.x_dict['price_obs'][indices, :, :] == subset.x_dict['price_obs'])\n",
    "assert torch.all(dataset.label[indices] == subset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 2, 0, 3])\n",
      "tensor([2, 1, 2, 0, 3])\n",
      "tensor([3, 2, 3, 1, 4])\n",
      "tensor([2, 1, 2, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "print(subset.label)\n",
    "print(dataset.label[indices])\n",
    "\n",
    "subset.label += 1  # modifying the batch does not change the original dataset.\n",
    "\n",
    "print(subset.label)\n",
    "print(dataset.label[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139957071248016\n",
      "139957071266896\n"
     ]
    }
   ],
   "source": [
    "print(id(subset.label))\n",
    "print(id(dataset.label[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch dataloader for the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler, SequentialSampler, RandomSampler\n",
    "shuffle = False\n",
    "batch_size = 32\n",
    "\n",
    "sampler = BatchSampler(\n",
    "    RandomSampler(dataset) if shuffle else SequentialSampler(dataset),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         sampler=sampler,\n",
    "                                         num_workers=0,  # 0 if dataset.device == 'cuda' else os.cpu_count(),\n",
    "                                         collate_fn=lambda x: x[0],\n",
    "                                         pin_memory=(dataset.device == 'cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_obs.shape=torch.Size([4, 64])\n",
      "item_obs_all.shape=torch.Size([10000, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f'{item_obs.shape=:}')\n",
    "item_obs_all = item_obs.view(1, num_items, -1).expand(num_sessions, -1, -1)\n",
    "item_obs_all = item_obs_all.to(dataset.device)\n",
    "label_all = label.to(dataset.device)\n",
    "print(f'{item_obs_all.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    # check consistency.\n",
    "    first, last = i * batch_size, min(len(dataset), (i + 1) * batch_size)\n",
    "    idx = torch.arange(first, last)\n",
    "    assert torch.all(item_obs_all[idx, :, :] == batch.x_dict['item_obs'])\n",
    "    assert torch.all(label_all[idx] == batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Multiple Datasets: `JointDataset` Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset.clone()\n",
    "dataset2 = dataset.clone()\n",
    "joint_dataset = JointDataset(the_dataset=dataset1, another_dataset=dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JointDataset with 2 sub-datasets: (\n",
       "\tthe_dataset: ChoiceDataset(label=[10000], user_onehot=[10000, 10], item_availability=[10000, 4], variable_types=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[10000, 234], taste_obs=[10, 4, 567], price_obs=[10000, 4, 12], device=cuda:0)\n",
       "\tanother_dataset: ChoiceDataset(label=[10000], user_onehot=[10000, 10], item_availability=[10000, 4], variable_types=[5], user_obs=[10, 128], item_obs=[4, 64], session_obs=[10000, 234], taste_obs=[10, 4, 567], price_obs=[10000, 4, 12], device=cuda:0)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7dc80b2c4d9dbaf52e273e24444ebf2c26f0fdc466c7e783c99ad3a1ce41bbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
