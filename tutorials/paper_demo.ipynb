{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials for Torch-Choice Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_choice\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from torch_choice.data import ChoiceDataset, utils\n",
    "from torch_choice.model import ConditionalLogitModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Car Choice Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import torch_choice\n",
    "import torch_choice.utils\n",
    "from torch_choice.utils.easy_data_wrapper import EasyDatasetWrapper\n",
    "from torch_choice.utils.run_helper import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmark\n",
    "**Copy the following description to the paper**.\n",
    "We designed a simple performance benchmark based on the transportation choice dataset: we duplicates $K$ copies of the original dataset of 2779 observations and compare time taken by various implementations. We compared the time cost of only the estimation process, since there are ample possibilities for further optimizing the estimation process (e.g., tuning learning rates, early stopping), we could under-estimate performances here. However, we wish to highlight how K \n",
    "The metric $\\frac{\\text{log-likelihood}}{K}$ is used to check that various optimizers converged to the same solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p './benchmark_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 3\n",
    "df = pd.read_csv('./public_datasets/ModeCanada.csv')\n",
    "df_list = list()\n",
    "num_cases = df['case'].max()\n",
    "for i in range(num_copies):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['case'] += num_cases * i\n",
    "    df_list.append(df_copy)\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>case</th>\n",
       "      <th>alt</th>\n",
       "      <th>choice</th>\n",
       "      <th>dist</th>\n",
       "      <th>cost</th>\n",
       "      <th>ivt</th>\n",
       "      <th>ovt</th>\n",
       "      <th>freq</th>\n",
       "      <th>income</th>\n",
       "      <th>urban</th>\n",
       "      <th>noalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>15.77</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>15.77</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46555</th>\n",
       "      <td>15516</td>\n",
       "      <td>12970</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "      <td>65.93</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46556</th>\n",
       "      <td>15517</td>\n",
       "      <td>12971</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>60.60</td>\n",
       "      <td>193</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46557</th>\n",
       "      <td>15518</td>\n",
       "      <td>12971</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>323</td>\n",
       "      <td>61.37</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46558</th>\n",
       "      <td>15519</td>\n",
       "      <td>12972</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>28.50</td>\n",
       "      <td>63</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46559</th>\n",
       "      <td>15520</td>\n",
       "      <td>12972</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>28.50</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46560 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   case    alt  choice  dist   cost  ivt  ovt  freq  income  \\\n",
       "0               1      1  train       0    83  28.25   50   66     4      45   \n",
       "1               2      1    car       1    83  15.77   61    0     0      45   \n",
       "2               3      2  train       0    83  28.25   50   66     4      25   \n",
       "3               4      2    car       1    83  15.77   61    0     0      25   \n",
       "4               5      3  train       0    83  28.25   50   66     4      70   \n",
       "...           ...    ...    ...     ...   ...    ...  ...  ...   ...     ...   \n",
       "46555       15516  12970    car       1   347  65.93  267    0     0      35   \n",
       "46556       15517  12971  train       0   323  60.60  193  200     3      45   \n",
       "46557       15518  12971    car       1   323  61.37  278    0     0      45   \n",
       "46558       15519  12972  train       0   150  28.50   63  105     1      70   \n",
       "46559       15520  12972    car       1   150  28.50  134    0     0      70   \n",
       "\n",
       "       urban  noalt  \n",
       "0          0      2  \n",
       "1          0      2  \n",
       "2          0      2  \n",
       "3          0      2  \n",
       "4          0      2  \n",
       "...      ...    ...  \n",
       "46555      0      3  \n",
       "46556      0      2  \n",
       "46557      0      2  \n",
       "46558      0      2  \n",
       "46559      0      2  \n",
       "\n",
       "[46560 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_mode_canada_datasets(num_copies: int):\n",
    "    df = pd.read_csv('./public_datasets/ModeCanada.csv', index_col=0)\n",
    "    df_list = list()\n",
    "    num_cases = df['case'].max()\n",
    "    for i in range(num_copies):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['case'] += num_cases * i\n",
    "        df_list.append(df_copy)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    df = df.query('noalt == 4').reset_index(drop=True)\n",
    "    df.sort_values(by='case', inplace=True)\n",
    "    item_index = df[df['choice'] == 1].sort_values(by='case')['alt'].reset_index(drop=True)\n",
    "    item_names = ['air', 'bus', 'car', 'train']\n",
    "    num_items = 4\n",
    "    encoder = dict(zip(item_names, range(num_items)))\n",
    "    item_index = item_index.map(lambda x: encoder[x])\n",
    "    item_index = torch.LongTensor(item_index)\n",
    "    price_cost_freq_ovt = utils.pivot3d(df, dim0='case', dim1='alt',\n",
    "                                        values=['cost', 'freq', 'ovt'])\n",
    "    price_ivt = utils.pivot3d(df, dim0='case', dim1='alt', values='ivt')\n",
    "    session_income = df.groupby('case')['income'].first()\n",
    "    session_income = torch.Tensor(session_income.values).view(-1, 1)\n",
    "\n",
    "    # session_index = torch.arange(len(session_income))\n",
    "    \n",
    "    dataset = ChoiceDataset(\n",
    "        # item_index=item_index.repeat(num_copies),\n",
    "        item_index=item_index,\n",
    "        session_index=torch.arange(len(session_income)),\n",
    "        price_cost_freq_ovt=price_cost_freq_ovt,\n",
    "        session_income=session_income,\n",
    "        price_ivt=price_ivt)\n",
    "    return df, dataset.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dataset = duplicate_mode_canada_datasets(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:08<00:00, 62.69s/it]\n"
     ]
    }
   ],
   "source": [
    "performance_records = list()\n",
    "# k_range = [1, 5, 10, 100, 1_000, 10_000]\n",
    "k_range = [50, 500, 5_000]\n",
    "dataset_at_k = dict()\n",
    "for k in tqdm(k_range):\n",
    "    df, dataset = duplicate_mode_canada_datasets(k)\n",
    "    dataset_at_k[k] = dataset.clone()\n",
    "    # df.to_csv(f'./benchmark_data/mode_canada_{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (price_cost_freq_ovt): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, device=cpu).\n",
      "    (session_income): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "    (price_ivt): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, device=cpu).\n",
      "    (intercept): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[price_cost_freq_ovt] with 3 parameters, with constant level variation.\n",
      "X[session_income] with 1 parameters, with item level variation.\n",
      "X[price_ivt] with 1 parameters, with item-full level variation.\n",
      "X[intercept] with 1 parameters, with item level variation.\n",
      "device=cpu\n",
      "==================== received dataset ====================\n",
      "ChoiceDataset(label=[], item_index=[27790], provided_num_items=[], user_index=[], session_index=[27790], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu)\n",
      "==================== training the model ====================\n",
      "Epoch 100: Log-likelihood=-44074.7265625\n",
      "Epoch 200: Log-likelihood=-29754.7890625\n",
      "Epoch 300: Log-likelihood=-23659.138671875\n",
      "Epoch 400: Log-likelihood=-21073.43359375\n",
      "Epoch 500: Log-likelihood=-18857.978515625\n",
      "Epoch 600: Log-likelihood=-18838.84375\n",
      "Epoch 700: Log-likelihood=-18827.517578125\n",
      "Epoch 800: Log-likelihood=-18819.5078125\n",
      "Epoch 900: Log-likelihood=-18813.14453125\n",
      "Epoch 1000: Log-likelihood=-18807.544921875\n"
     ]
    }
   ],
   "source": [
    "for k in k_range:\n",
    "    # run for 3 times.\n",
    "    for _ in range(3):\n",
    "        dataset = duplicate_mode_canada_datasets(k)\n",
    "        model = model = ConditionalLogitModel(\n",
    "            formula='(price_cost_freq_ovt|constant) + (session_income|item) + (price_ivt|item-full) + (intercept|item)',\n",
    "            dataset=dataset,\n",
    "            num_items=4)\n",
    "        # only time the model estimation.\n",
    "        start_time = time()\n",
    "        model, ll = run(model, dataset, batch_size=-1, learning_rate=0.03 , num_epochs=1000, compute_std=True, return_final_training_log_likelihood=True)\n",
    "        end_time = time()\n",
    "        performance_records.append(dict(k=k, time=end_time - start_time, ll=ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Setup (Depreciated)\n",
    "Example utility construction:\n",
    "$$\n",
    "U_{uis} = \\lambda_i + \\beta_u^\\top \\bm{x}_\\text{item}^{(i)} + \\gamma^\\top \\bm{x}_\\text{session}^{(s)} + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.15 ('python-dev')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n python-dev ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "num_items = 10\n",
    "num_users = 5\n",
    "num_sessions = 1\n",
    "N = 50000\n",
    "# generate a random user ui.\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=N))\n",
    "# construct users.\n",
    "# item_index = torch.LongTensor(np.random.choice(num_items, size=N))\n",
    "# construct sessions.\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=N))\n",
    "rational_prob = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_obs = torch.rand(num_users, 3)\n",
    "item_obs = torch.rand(num_items, 3)\n",
    "session_obs = torch.rand(num_sessions, 3)\n",
    "# price_obs = torch.randn(num_sessions, num_items, 12)\n",
    "item_index = torch.LongTensor(np.random.choice(num_items, size=N))\n",
    "user_index = torch.LongTensor(np.random.choice(num_users, size=N))\n",
    "session_index = torch.LongTensor(np.random.choice(num_sessions, size=N))\n",
    "item_availability = torch.ones(num_sessions, num_items).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_item = torch.rand(num_items) * 10\n",
    "lambda_item[0] = 0\n",
    "beta_user = torch.rand(num_users, item_obs.shape[-1]) * 10\n",
    "gamma_constant = torch.rand(session_obs.shape[-1]) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:00<00:00, 64854.88it/s]\n"
     ]
    }
   ],
   "source": [
    "item_index = list()\n",
    "\n",
    "for n in tqdm(range(N)):\n",
    "    u, s = user_index[n], session_index[n]\n",
    "    if np.random.rand() <= rational_prob:\n",
    "        # (num_items, 1)\n",
    "        # utilities = lambda_item + (beta_user[u].view(1, -1).expand(num_items, -1) * item_obs).sum(dim=-1) + (gamma_constant.view(1, -1).expand(num_items, -1) * session_obs[s].view(1, -1).expand(num_items, -1)).sum(dim=-1)\n",
    "        utilities = lambda_item\n",
    "        p = torch.nn.functional.softmax(utilities, dim=0).detach().numpy()\n",
    "        item_index.append(np.random.choice(num_items, p=p))\n",
    "        # item_index.append(int(np.argmax(utilities)))\n",
    "    else:\n",
    "        item_index.append(int(np.random.choice(num_items, size=1)))\n",
    "item_index = torch.LongTensor(item_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'item_index': item_index, 'user_index': user_index, 'session_index': session_index})\n",
    "df.to_csv('./benchmark_data/choice_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDataset(label=[], item_index=[50000], provided_num_items=[1], user_index=[50000], session_index=[50000], item_availability=[], item_obs=[10, 3], user_obs=[5, 3], session_obs=[1, 3], device=cpu)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ChoiceDataset(item_index=item_index, user_index=user_index, session_index=session_index, item_obs=item_obs, user_obs=user_obs, session_obs=session_obs, num_items=num_items)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConditionalLogitModel(\n",
       "  (coef_dict): ModuleDict(\n",
       "    (intercept): Coefficient(variation=item, num_items=10, num_users=5, num_params=1, 9 trainable parameters in total, device=cpu).\n",
       "  )\n",
       ")\n",
       "Conditional logistic discrete choice model, expects input features:\n",
       "\n",
       "X[intercept] with 1 parameters, with item level variation.\n",
       "device=cpu"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = ConditionalLogitModel(formula='(1|item-full) + (item_obs|user) + (session_obs|constant)', dataset=dataset, num_items=num_items, num_users=num_users)\n",
    "model = ConditionalLogitModel(formula='(1|item)', dataset=dataset, num_items=num_items, num_users=num_users)\n",
    "print(np.mean((model(dataset).argmax(dim=1) == item_index).float().numpy()))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (intercept): Coefficient(variation=item, num_items=10, num_users=5, num_params=1, 9 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[intercept] with 1 parameters, with item level variation.\n",
      "device=cpu\n",
      "==================== received dataset ====================\n",
      "ChoiceDataset(label=[], item_index=[50000], provided_num_items=[1], user_index=[50000], session_index=[50000], item_availability=[], item_obs=[10, 3], user_obs=[5, 3], session_obs=[1, 3], device=cpu)\n",
      "==================== training the model ====================\n",
      "Epoch 100: Log-likelihood=-81310.9375\n",
      "Epoch 200: Log-likelihood=-81305.359375\n",
      "Epoch 300: Log-likelihood=-81305.2421875\n",
      "Epoch 400: Log-likelihood=-81305.2265625\n",
      "Epoch 500: Log-likelihood=-81305.234375\n",
      "Epoch 600: Log-likelihood=-81305.2265625\n",
      "Epoch 700: Log-likelihood=-81308.171875\n",
      "Epoch 800: Log-likelihood=-81305.2265625\n",
      "Epoch 900: Log-likelihood=-81339.671875\n",
      "Epoch 1000: Log-likelihood=-81305.234375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40572"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run(model, dataset, batch_size=-1, learning_rate=0.3 , num_epochs=1000, compute_std=False)\n",
    "np.mean((model(dataset).argmax(dim=1) == item_index).float().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7301, 6.1908, 7.1181],\n",
       "        [3.4178, 8.8197, 4.9632],\n",
       "        [4.9116, 4.5997, 0.7213],\n",
       "        [8.3757, 0.5155, 4.8729],\n",
       "        [8.5097, 6.4045, 2.3534]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'item_obs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r3/rj0t5xcj557855yt3xr0qwnh0000gn/T/ipykernel_79509/1385705425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_copy_to_script_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'item_obs'"
     ]
    }
   ],
   "source": [
    "model.coef_dict['item_obs'].coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 6.0579, 0.8783, 7.2887, 6.3035, 1.2217, 4.7925, 6.6317, 4.6998,\n",
       "        5.0522])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.1896, -1.4328,  4.4139,  3.4304, -1.5620,  1.9348,  3.7506,  1.8674,\n",
       "         2.2129], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_dict['intercept'].coef.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1350, 8.2167, 7.8468])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0625, -2.9416, -0.7111], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_dict['session_obs'].coef.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40572"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((model(dataset).argmax(dim=1) == item_index).float().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('python-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d92ea78b472bc7f2f6d2f7070651103d53ad43bfc70c0f5af1739623a72c3e1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
