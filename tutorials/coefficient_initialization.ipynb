{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559e3b77",
   "metadata": {},
   "source": [
    "# Coefficient Initialization\n",
    "\n",
    "> Tianyu Du\n",
    "> \n",
    "> Added since version `1.0.4`\n",
    "\n",
    "[From ChatGPT] Coefficient initialization is an essential component of model estimation, especially in the context of machine learning and deep learning. The choice of initial coefficients can dramatically impact the efficiency, speed, and even the ultimate success of model training. Poor initialization can lead to slow convergence during the optimization process or result in the model getting stuck in suboptimal local minima, particularly in models with non-convex loss landscapes such as neural networks. Additionally, it can exacerbate the problem of vanishing or exploding gradients, inhibiting the backpropagation process. Conversely, thoughtful and strategic initialization, like Xavier or He initialization, can lead to faster convergence, better generalization performance, and more robust models. Thus, the way coefficients are initialized can significantly influence the effectiveness and reliability of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8477dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_choice\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17425fd5",
   "metadata": {},
   "source": [
    "# Conditional Logit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c937c6",
   "metadata": {},
   "source": [
    "## By default, coefficients are initialized following a standard Gaussian distribution.\n",
    "\n",
    "Here we create a \"big\" model of thousands of parameters to illustrate the distribution of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.ConditionalLogitModel(\n",
    "    coef_variation_dict={'var_1': 'constant', 'var_2': 'item', 'var_3': 'item-full', 'var_4': 'user'},\n",
    "    num_param_dict={'var_1': 300, 'var_2': 500, 'var_3': 700, 'var_4': 900},\n",
    "    num_items=4,\n",
    "    num_users=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_initial_coefficients(model_to_plot: torch.nn.Module) -> None:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 4), dpi=150)\n",
    "\n",
    "    for i, (coef_name, coef_value) in enumerate(model_to_plot.state_dict().items()):\n",
    "        arr = coef_value.view(-1,).to(\"cpu\").numpy()\n",
    "        axes[i].hist(arr, bins=40)\n",
    "        axes[i].set_title(f\"{coef_name} (K={len(arr)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f97453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f397f",
   "metadata": {},
   "source": [
    "## Alternatively, you can initialize to uniform or zeros using the `weight_initialization` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13188ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.ConditionalLogitModel(\n",
    "    coef_variation_dict={'var_1': 'constant', 'var_2': 'item', 'var_3': 'item-full', 'var_4': 'user'},\n",
    "    num_param_dict={'var_1': 300, 'var_2': 500, 'var_3': 700, 'var_4': 900},\n",
    "    num_items=4,\n",
    "    num_users=10,\n",
    "    weight_initialization=\"uniform\")\n",
    "\n",
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.ConditionalLogitModel(\n",
    "    coef_variation_dict={'var_1': 'constant', 'var_2': 'item', 'var_3': 'item-full', 'var_4': 'user'},\n",
    "    num_param_dict={'var_1': 300, 'var_2': 500, 'var_3': 700, 'var_4': 900},\n",
    "    num_items=4,\n",
    "    num_users=10,\n",
    "    weight_initialization=\"zero\")\n",
    "\n",
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.ConditionalLogitModel(\n",
    "    coef_variation_dict={'var_1': 'constant', 'var_2': 'item', 'var_3': 'item-full', 'var_4': 'user'},\n",
    "    num_param_dict={'var_1': 300, 'var_2': 500, 'var_3': 700, 'var_4': 900},\n",
    "    num_items=4,\n",
    "    num_users=10,\n",
    "    weight_initialization=\"normal\")\n",
    "\n",
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7795717",
   "metadata": {},
   "source": [
    "## You can initialize different sets of coefficients differently by passing a dictionary to `weight_initialization`. For coefficients not in `weight_initialization`, they are initialized as a standard normal distribution (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c30740",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.ConditionalLogitModel(\n",
    "    coef_variation_dict={'var_1': 'constant', 'var_2': 'item', 'var_3': 'item-full', 'var_4': 'user'},\n",
    "    num_param_dict={'var_1': 300, 'var_2': 500, 'var_3': 700, 'var_4': 900},\n",
    "    num_items=4,\n",
    "    num_users=10,\n",
    "    weight_initialization={'var_1': 'uniform',\n",
    "                           'var_2': 'normal',\n",
    "                           'var_3': 'zero'})  # <-- 'var_4' is missing, and it's initialized using Gaussian.\n",
    "\n",
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6efad",
   "metadata": {},
   "source": [
    "## You can inspect the method of initialization in the string representation of model coefficients (e.g., `initialization=normal`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3e50f",
   "metadata": {},
   "source": [
    "# Nested Logit Model\n",
    "\n",
    "Initializing nested logit models is very similar to initializing conditional logit models. The only difference is you need to pass-in two arguments: `nest_weight_initialization` and `item_weight_initialization`. By default, every coefficient is initialized to a standard Gaussian distribution. The coefficient for inclusive values $\\lambda$ has its own way of initialization and cannot be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a22588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_choice.model.NestedLogitModel(\n",
    "    nest_to_item={1: [0, 1, 2], 2: [3, 4], 3: [5, 6, 7]},\n",
    "    #\n",
    "    nest_coef_variation_dict={'var_1': 'constant', 'var_2': 'item'},\n",
    "    nest_num_param_dict={'var_1': 300, 'var_2': 500},\n",
    "    #\n",
    "    item_coef_variation_dict={'var_3': 'item-full', 'var_4': 'user'},\n",
    "    item_num_param_dict={'var_3': 700, 'var_4': 900},\n",
    "    num_users=100,\n",
    "    # \n",
    "    nest_weight_initialization={'var_1': 'uniform', 'var_2': 'zero'},\n",
    "    item_weight_initialization={'var_4': 'uniform'}   # <-- var_3 is missing, it is initialized to Gaussian by default.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc812279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_initial_coefficients(model_to_plot: torch.nn.Module) -> None:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(25, 4), dpi=150)\n",
    "\n",
    "    for i, (coef_name, coef_value) in enumerate(model_to_plot.state_dict().items()):\n",
    "        arr = coef_value.view(-1,).to(\"cpu\").numpy()\n",
    "        axes[i].hist(arr, bins=40)\n",
    "        axes[i].set_title(f\"{coef_name} (K={len(arr)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b667a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_initial_coefficients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03c186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
